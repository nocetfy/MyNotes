import{_ as o,X as l,Y as c,Z as n,a0 as a,a1 as t,$ as e,H as i}from"./framework-1ee2252c.js";const p={},d=e(`<h1 id="缓存" tabindex="-1"><a class="header-anchor" href="#缓存" aria-hidden="true">#</a> 缓存</h1><p>[toc]</p><h2 id="前言" tabindex="-1"><a class="header-anchor" href="#前言" aria-hidden="true">#</a> 前言</h2><p>从CPU Cache Line到MESI，到LOCK指令，内存屏障、JMM与可见性，总结它们之间的区别与联系。</p><hr><h2 id="cache-line" tabindex="-1"><a class="header-anchor" href="#cache-line" aria-hidden="true">#</a> Cache Line</h2><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/Cache的数据结构.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>​ 高速缓存的组成由S个<code>高速缓存组</code>(cache set)，每一组包含E个<code>高速缓存行</code>（cache line) ，每一行由一个<code>有效位（valid bit）</code>指明这个行是否包含有意义的信息；一个长度为t的<code>标记位（tag bit ）</code>，唯一标识存储在这个高速缓存行中的块在内存中的地址；和一个B字节的<code>数据块（block）</code>构成。</p><blockquote><p>64位CPU缓存行的大小一般为64个字节（不包含有效位和标记位）</p></blockquote><h3 id="伪共享" tabindex="-1"><a class="header-anchor" href="#伪共享" aria-hidden="true">#</a> 伪共享</h3><p>​ 缓存中交换数据的最小单位是缓存行，所以如果一个共享变量被多个cpu核心所使用时，就会出现相同的主内存块号内容被缓存到不同的缓存行中，如果一个cpu核心对它所关心的变量进行了修改，就会导致另一个cpu核心的缓存行失效，产生缓存未命中，如果这样的情况经常发生，会严重的影响程序性能，这就是<strong>伪共享</strong>，它会严重浪费系统资源。</p><p>​ 其实伪共享产生的本质问题是，<strong>不同CPU使用到的数据，被缓存在相同的缓存行中</strong>，只要可以解决此问题，就会消除伪共享。</p><h3 id="java中解决伪共享" tabindex="-1"><a class="header-anchor" href="#java中解决伪共享" aria-hidden="true">#</a> Java中解决伪共享</h3><p>通过数据填充的方式，保证变量不会和其他东西同时存在于一个缓存行中，这样失去了地址连续性被加载到同一个缓存行，就避免了伪共享。</p><div class="language-java line-numbers-mode" data-ext="java"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FalseSharingTest</span> <span class="token punctuation">{</span>
    <span class="token comment">//核心数据</span>
    <span class="token keyword">private</span> <span class="token keyword">volatile</span> <span class="token keyword">long</span> value<span class="token punctuation">;</span>
    <span class="token comment">// cache line padding</span>
    <span class="token keyword">private</span> <span class="token keyword">long</span> p1<span class="token punctuation">,</span> p2<span class="token punctuation">,</span> p3<span class="token punctuation">,</span> p4<span class="token punctuation">,</span> p5<span class="token punctuation">,</span> p6 <span class="token operator">=</span> <span class="token number">1L</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>比较有名的<strong>Disruptor</strong>框架就采用了这种解决办法提高性能。</p><h4 id="jdk7解决" tabindex="-1"><a class="header-anchor" href="#jdk7解决" aria-hidden="true">#</a> JDK7解决</h4><p>​ 由于<strong>JDK7会编译期间会淘汰或者是重新排列无用的字段</strong>，所以原来的填充long类型无用字段的办法在JDK7下就失效了，但是伪共享依然会发生，但是将用于填充的long字段写到父类同样可以解决伪共享。</p><div class="language-java line-numbers-mode" data-ext="java"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FalseSharing</span> <span class="token punctuation">{</span>
    <span class="token comment">// cache line padding</span>
    <span class="token keyword">private</span> <span class="token keyword">long</span> p1<span class="token punctuation">,</span> p2<span class="token punctuation">,</span> p3<span class="token punctuation">,</span> p4<span class="token punctuation">,</span> p5<span class="token punctuation">,</span> p6 <span class="token operator">=</span> <span class="token number">1L</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
<span class="token keyword">class</span> <span class="token class-name">FalseSharingTest</span>  <span class="token keyword">extends</span> <span class="token class-name">FalseSharing</span><span class="token punctuation">{</span>
    <span class="token comment">// 核心数据</span>
    <span class="token keyword">private</span> <span class="token keyword">volatile</span> <span class="token keyword">long</span> value<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="jdk8解决" tabindex="-1"><a class="header-anchor" href="#jdk8解决" aria-hidden="true">#</a> JDK8解决</h4><p>​ Java8中，Java官方已经提供了对伪共享的解决办法，那就是<code>sun.misc.Contended</code>注解。要注意的是直接使用此注解默认是无效的，需要在jvm启动时设置<code>-XX:-RestrictContended</code></p><hr><h2 id="mesi" tabindex="-1"><a class="header-anchor" href="#mesi" aria-hidden="true">#</a> MESI</h2><p>​ <code>MESI</code>是众多缓存一致性协议中的一种，也在Intel系列中广泛使用的缓存一致性协议。<code>缓存行（Cache line）</code>的状态有<code>Modified</code>、Exclusive、 <code>Share</code> 、<code>Invalid</code>，而MESI 命名正是以这4中状态的首字母来命名的。该协议要求在每个缓存行上维护两个状态位，使得每个数据单位可能处于M、E、S和I这四种状态之一,各种状态含义如下：</p><table><thead><tr><th style="text-align:left;">状态</th><th style="text-align:left;">含义</th><th style="text-align:left;">描述</th></tr></thead><tbody><tr><td style="text-align:left;">M</td><td style="text-align:left;">修改</td><td style="text-align:left;">表示缓存行数据被修改了，并且没有更新至主内存。处于这一状态的数据，只在本CPU中有缓存数据，而其他CPU中没有。简单的可理解为<strong>缓存行数据独占被修改且未同步</strong></td></tr><tr><td style="text-align:left;">E</td><td style="text-align:left;">独享（互斥）</td><td style="text-align:left;">表示缓存行数据是独占的。处于这一状态的数据，只有在本CPU中有缓存，其它CPU中没有缓存该数据，且其数据没有修改与主内存中一致。简单的可理解为<strong>缓存行数据独占且未被修改</strong></td></tr><tr><td style="text-align:left;">S</td><td style="text-align:left;">共享</td><td style="text-align:left;">表示缓存行数据是共享的。处于这一状态的数据在多个CPU中都有缓存，且与内存一致</td></tr><tr><td style="text-align:left;">I</td><td style="text-align:left;">无效</td><td style="text-align:left;">表示缓存行数据是无效的。本CPU中的这份缓存已经无效。</td></tr></tbody></table><p><em>上面对于<code>S</code>状态的描述，我们可能会想到另一种状态，数据被共享但是与内存中不一致的情况，这就是我们MESI协议需要解决的问题</em></p><h3 id="mesi如何保证缓存一致性" tabindex="-1"><a class="header-anchor" href="#mesi如何保证缓存一致性" aria-hidden="true">#</a> MESI如何保证缓存一致性</h3><p>MESI协议对不同的状态增了不同的<strong>监听任务</strong>，监听任务的规则如下</p><ul><li>一个处于<code>M</code>状态的缓存行，必须时刻监听所有<code>试图读取</code>该缓存行对应的主存地址的操作，如果监听到，则必须在此操作执行前把其缓存行中的<code>数据写回主内存</code></li><li>一个处于<code>S</code>状态的缓存行，必须时刻监听使该缓存行<code>无效</code>或者<code>独享</code>该缓存行的请求，如果监听到，则必须把其缓存行状态设置为<code>I</code>。</li><li>一个处于<code>E</code>状态的缓存行，必须时刻监听其他试图<code>读取</code>该缓存行对应的主存地址的操作，如果监听到，则必须把其缓存行状态设置为S。</li></ul><h3 id="mesi消息" tabindex="-1"><a class="header-anchor" href="#mesi消息" aria-hidden="true">#</a> MESI消息</h3><table><thead><tr><th style="text-align:left;">消息名</th><th style="text-align:left;">消息类型</th><th style="text-align:left;">描述</th></tr></thead><tbody><tr><td style="text-align:left;">Read</td><td style="text-align:left;">请求</td><td style="text-align:left;">通知其它处理器，主内存当前处理器准备读取某个数据。该消息包含待读取数据的内存地址</td></tr><tr><td style="text-align:left;">Read Response</td><td style="text-align:left;">响应</td><td style="text-align:left;">该消息包含被请求的读取消息的数据。可能是主内存提供的，也可能是嗅探到Read消息的其它处Cache提供的，主要看嗅探到Read消息的Cache中缓存行的状态</td></tr><tr><td style="text-align:left;">Invalidate</td><td style="text-align:left;">请求</td><td style="text-align:left;">通知其它处理器将其高速缓存中指定内存地址对应的缓存行状态置为I（无效) ,也就是通知其它处理器将指定内存地址的副本数据删除</td></tr><tr><td style="text-align:left;">Invalidate Acknowledge</td><td style="text-align:left;">响应</td><td style="text-align:left;">接收到Invalidate消息的处理器必须回复此响应，以表示删除了其高速缓存上的相应副本数据（这里的删除是逻辑删除，其实只是更新了缓存条件的Flag值）</td></tr><tr><td style="text-align:left;">Read Invalidate</td><td style="text-align:left;">请求</td><td style="text-align:left;">从名字可以推断出该消息是一个复合消息，是由Read消息和Invalidate消息组合而成。它的作用是通知其它处理，发送该消息的处理器准备更新一个数据，请求其它处理器删除其高速缓存中相应的副本数据。接收到该消息的处理器必须回复两个响应消息，Read Response、Invalidate Acknowledge消息，发送该消息的处理器期望收到一个Read Response以及多个Invalidate Acknowledge。</td></tr><tr><td style="text-align:left;">Writeback</td><td style="text-align:left;">请求</td><td style="text-align:left;">该消息包含需要写入主内存的数据及其对应的内存地址</td></tr></tbody></table><h3 id="mesi协议的处理流程" tabindex="-1"><a class="header-anchor" href="#mesi协议的处理流程" aria-hidden="true">#</a> MESI协议的处理流程</h3><blockquote><p>在这里我们只讨论多核情况下的数据读取X，我们以两核为例，CPU A 拥有 L1 A高速缓存，CPU B拥有L1 B高速缓存</p></blockquote><p>MESI协议在数据的读定时，是通过往总线中<code>发送消息请求</code>和<code>响应</code>来保证数据的一致性的，下面我们看一下数据的读取流程</p><h4 id="数据读取流程" tabindex="-1"><a class="header-anchor" href="#数据读取流程" aria-hidden="true">#</a> 数据读取流程</h4><p>CPU A需要读取数据X，会根据数据的地址在自己的缓存L1 A中找到对应的缓存行,然后判断缓存行的状态</p><ul><li><p>如果缓存行的状态是<code>M、E、S</code>，说明该缓存行的数据对于当前读请求是<code>可用的</code>，直接从缓存行中获取地址A对应的数据</p></li><li><p>如果缓存行的状态是<code>I</code>，则说明该缓存行的数据<code>是无效的</code>，则CPUA会向总线发送<code>Read消息</code>，说<strong>我现在需要地址A的数据，谁可以提供?</strong>，其它处理器（CPU B）会监听总线上的消息，收到消息后，会从消息中解析出需要读取的地址，然后在自己缓存（L1B）中查找缓存行，这时候根据找到缓存行的状态会有以下几种情况</p><ul><li><p>状态为<code>S/E</code> , CPU B会构造<code>Read Response</code>消息，将相应缓存行中的数据放到消息中，发送到总线同时更新自己缓存行的状态为<code>S</code>，CPU A收到响应消息后，会将消息中的数据存入相应的缓存行中，同时更新缓存行的状态为<code>S</code></p></li><li><p>状态为<code>M</code>，会先将自己缓存行中的数据写入主内存，并响应<code>Read Response</code>消息同时将L1 B中的相应的缓存行状态更新为<code>S</code></p></li><li><p>状态为<code>I</code>或者在自己的缓存中不存在地址A的数据，那么主内存会构造<code>Read Response</code>消息，从主内存读取包含指定地址的块号数据放入消息（缓存行大小和内存块大小一致所以可以存放的下），并将消息发送到总线</p><p>CPU A获接收到总线消息之后，解析出数据保存在自己的缓存中</p></li></ul></li></ul><h4 id="写流程" tabindex="-1"><a class="header-anchor" href="#写流程" aria-hidden="true">#</a> 写流程</h4><p>CPUA需要对地址A的X数据进行写操作</p><blockquote><p>任何一个处理器执行内存操作时，必须拥有相应数据的所有权。</p></blockquote><p>CPU A会先根据内存地址在自己的缓存中L1 A中找相应的缓存行,判断缓存行的不同状态，可能会了现下列几种情况</p><ol><li>为<code>E/M</code>时，说明当前CPU A已经拥有了相应数据的所有权，此时CPU A会直接将数据写入缓存行中，并更新缓存行状态为M，此时不需要向总线发送任何消息。</li><li><code>S</code>时，说明数据被共享，其它CPU中有可能存有该数据的副本，则CPUA向总线发送<code>Invalidate 消息</code>以获取数据的所有权，其它处理器（CPU B)收到<code>Invalidate消息</code>后,会将其高速缓存中相应的缓存行状态更新为<code>I</code>，表示已经逻辑删除相应的副本数据，并回<code>复Invalidate Acknowledge</code>消息，CPU A收到所有处理器的响应消息后，会将数据更新到相应的缓存行之中，同时修改缓存行状态为<code>E</code>，此时拥有数据的所有权，会对缓存行数据进行更新，最终该缓存行状态为<code>M</code></li><li><code>I</code>时，说明当前处理器中不包含该数据的有效副本，则CPU A向总线发送<code>Read Invalidate消息</code> ，表明<strong>我要读数据X，希望主存告诉我X的值，同时请示其它处理器将自己缓存中包含该数据的缓存行并且状态不是I的缓存行置为无效</strong></li></ol><ul><li>其它处理器（CPU B)收到<code>Invalidate 消息</code>后，如果缓存行不为<code>I</code>的话，会将其高速缓存中相应的缓存行状态更新为<code>I</code>，表示已经逻辑删除相应的副本数据，并回复<code>Invalidate Acknowledge消息</code></li><li>主内存收到<code>Read消息</code>后，会响应<code>Read Response消息</code>将需要读取的数据告诉CPU A</li><li>CPU A收到所有处理器的<code>Invalidate Acknowledge消息</code>和主内存的<code>Read Response消息</code>后，会将数据更新到相应的缓存行之中，同时修改缓存行状态为<code>E</code>，此时拥有数据的所有权，会对缓存行数据进行更新，最终该缓存行状态为<code>M</code></li></ul><h3 id="mesi会有哪些问题" tabindex="-1"><a class="header-anchor" href="#mesi会有哪些问题" aria-hidden="true">#</a> MESI会有哪些问题</h3><p>​ 从上面处理过程中，其实不难发现，MESI主要是靠在总线上传递消息,并对消息增加不同的监听，来保证一个线程对共享变量的更新，对其它处理器上运行的线程是可见。但是消息传递是要时间的，一个请求，多个响应，每次都会涉及到CPU的切换，对于CPU这么频繁的读取，消息传递产生的时间是一种致命的影响，会导致<strong>引起缓存一致性流量风暴</strong>，导致各种各样的性能问题和稳定性问题。</p><h3 id="mesi频繁的消息请求与响应带来的性能问题如何解决" tabindex="-1"><a class="header-anchor" href="#mesi频繁的消息请求与响应带来的性能问题如何解决" aria-hidden="true">#</a> MESI频繁的消息请求与响应带来的性能问题如何解决?</h3><p><strong>现代的 CPU 会在增加写缓冲区和失效队列将 MESI 协议的请求异步化，以提高并行度：</strong></p><ul><li><strong>写缓冲区（Store Buffer）</strong></li></ul><p>​ 由于在写入操作之前，CPU 核心 1 需要先广播 RFO 请求获得独占权，在其它核心回应 ACK 之前，当前核心只能空等待，这对 CPU 资源是一种浪费。因此，现代 CPU 会采用 “写缓冲区” 机制：写入指令放到写缓冲区后并发送 RFO 请求后，CPU 就可以去执行其它任务，等收到 ACK 后再将写入操作写到 Cache 上。</p><ul><li><strong>失效队列（Invalidation Queue）</strong></li></ul><p>​ 由于其他核心在收到 RFO 请求时，需要及时回应 ACK。但如果核心很忙不能及时回复，就会造成发送 RFO 请求的核心在等待 ACK。因此，现代 CPU 会采用 “失效队列” 机制：先把其它核心发过来的 RFO 请求放到失效队列，然后直接返回 ACK，等当前核心处理完任务后再去处理失效队列中的失效请求。</p><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/image-20240211094650073.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>事实上，写缓冲区和失效队列破坏了 Cache 的一致性。</strong></p><h3 id="mesi总结" tabindex="-1"><a class="header-anchor" href="#mesi总结" aria-hidden="true">#</a> MESI总结</h3><p>​ CPU除了在做内存数据传输的时候和总线交互 ，而且还会通过不停在嗅探总线上发生的数据交换，跟踪其他缓存在做什么。当一个缓存代表它所属的处理器去读写内存时，其它处理器都会得到通知，以此来使自己的<code>缓存保持同步</code>。只要某个处理器一写内存，其它处理器马上知道这块内存在它们的缓存段中已失效。</p><hr><h2 id="cpu-lock指令" tabindex="-1"><a class="header-anchor" href="#cpu-lock指令" aria-hidden="true">#</a> CPU LOCK指令</h2><h3 id="cpu实现原子性" tabindex="-1"><a class="header-anchor" href="#cpu实现原子性" aria-hidden="true">#</a> CPU实现原子性</h3><p>​ 首先处理器会保证基本的内存操作的原子性，比如从内存读取或者写入一个字节是原子的，但对于<code>读-改-写</code>、或者是其它复杂的内存操作是不能保证其原子性的，又比如<code>跨总线宽度</code>、<code>跨多个缓存行</code>和<code>跨页表的访问</code>，这时候需要处理器提供<code>总线锁</code>和<code>缓存锁</code>两个机制来保证复杂的内存操作<code>原子性</code></p><h3 id="总线锁" tabindex="-1"><a class="header-anchor" href="#总线锁" aria-hidden="true">#</a> 总线锁</h3><p>​ LOCK#信号就是我们经常说到的<strong>总线锁</strong>，处理器使用<code>LOCK#</code>信号达到锁定总线，来解决原子性问题，当一个处理器往总线上输出LOCK#信号时，其它处理器的请求将被阻塞，此时该处理器此时独占共享内存。</p><p>总线锁这种做法锁定的范围太大了，导致CPU利用率急剧下降，因为使用LOCK#是把CPU和内存之间的通信锁住了，这使得锁定时期间，其它处理器不能操作其内存地址的数据 ，所以总线锁的开销比较大。</p><h3 id="缓存锁" tabindex="-1"><a class="header-anchor" href="#缓存锁" aria-hidden="true">#</a> 缓存锁</h3><p>​ 如果访问的内存区域已经缓存在处理器的缓存行中，P6系统和之后系列的处理器则不会声明LOCK#信号，它会对CPU的缓存中的缓存行进行锁定，在锁定期间，其它 CPU 不能同时缓存此数据，在修改之后，通过<code>缓存一致性</code>协议来保证修改的原子性，这个操作被称为<strong>缓存锁</strong>。</p><h3 id="cas" tabindex="-1"><a class="header-anchor" href="#cas" aria-hidden="true">#</a> CAS</h3><p>​ 关于CAS指令最著名的传闻是CAS需要锁总线，因此CAS指令不但慢而且会严重影响系统并发度，即使没有冲突是也一样。不过在较新的CPU中（对于Intel CPU来说是486之后），事实并非如此。目前的CPU一般都采用了很好的缓存一致性协议，在很多情况下能够防止锁总线的发生，这其中最著名的就是Intel CPU中使用的MESI缓存一致性协议。</p><p>​ 如果一个变量在某段时间内只被一个线程频繁修改，则对应的缓存早就处于M状态，<strong>这时CAS操作就不会涉及到总线操作</strong>。所以频繁的加锁并不一定会影响系统并发度，关键是看锁冲突的情况严重不严重，如果经常出现冲突，即缓存一会被这个CPU独占，一会被那个CPU独占，这时才会不断产生RFO，影响到并发性能。</p><p>​ 当两个<code>core</code>同时执行针对同一地址的CAS指令时，其实他们是在试图修改每个core自己持有的Cache line， 假设两个core都持有相同地址对应cache line，且各自cache line 状态为S, 这时如果要想成功修改，就首先需要把S转为E或者M， 则需要向其它core invalidate 这个地址的cache line，则两个core都会向ring bus 发出 invalidate这个操作, 那么在ringbus上就会根据特定的设计协议仲裁是core0，还是core1能赢得这个invalidate，胜者完成操作，失败者需要接受结果invalidate自己对应的cache line，再读取胜者修改后的值，回到起点。</p><p>​ 到这里, 我们可以发现MESIF协议大大降低了读操作的时延,没有让写操作更慢，同时保持了一致性。那么对于我们的CAS操作来说，其实锁并没有消失，只是转嫁到了ring bus的总线仲裁协议中。而且大量的多核同时针对一个地址的CAS操作会引起反复的互相invalidate 同一cache line，造成pingpong效应，同样会降低性能。</p><hr><h2 id="jmm" tabindex="-1"><a class="header-anchor" href="#jmm" aria-hidden="true">#</a> JMM</h2><p>​ 全称Java Memory Model（Java内存模型）是一个语言级别的内存模型抽象，它屏蔽了底层硬件实现内存一致性需求的差异，提供了对上层的统一的接口来提供保证内存一致性的编程能力。是一系列的Java虚拟机平台对开发者提供的多线程环境下的内存可见性、是否可以重排序等问题的无关具体平台的统一的保证。</p><p>​ JMM 与 JVM 内存区域的划分是不同的概念层次，更恰当说 JMM 描述的是一组规则，通过这组规则控制各个变量在共享数据区域内和私有数据区域的访问方式，<strong>JMM是围绕原子性、有序性、可见性展开</strong>。JMM 与 Java 内存区域唯一相似点，都存在共享数据区域和私有数据区域，在 JMM 中主内存属于共享数据区域，从某个程度上讲应该包括了堆和方法区，而工作内存数据线程私有数据区域，从某个程度上讲则应该包括程序计数器、虚拟机栈以及本地方法栈。</p><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/image-20240212095759778.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="指令重排序" tabindex="-1"><a class="header-anchor" href="#指令重排序" aria-hidden="true">#</a> 指令重排序</h3><p>从源码到指令执行一共有 3 种级别重排序：</p><ul><li><strong>编译器重排序：</strong> 例如将循环内重复调用的操作提前到循环外执行；</li><li><strong>指令重排序：</strong> 例如指令并行技术将多条指令重叠执行，或者使用分支预测技术提前执行分支的指令，并把计算结果放到重排列缓冲区（Reorder Buffer）的硬件缓存中，当程序真的进入分支后直接使用缓存中的结算结果；</li><li><strong>存储器系统重排序：</strong> 例如写缓冲区和失效队列机制，即是可见性问题，从内存的角度也是指令重排问题。</li></ul><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/webp" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>编译器重排序，JMM 提供了禁止特定类型的编译器重排序。 处理器重排序，JMM 会要求编译器生成指令时，会插入<strong>内存屏障</strong>来禁止处理器重排序。</p><h3 id="jmm解决原子性、可见性、有序性" tabindex="-1"><a class="header-anchor" href="#jmm解决原子性、可见性、有序性" aria-hidden="true">#</a> JMM解决原子性、可见性、有序性</h3><h4 id="原子性问题" tabindex="-1"><a class="header-anchor" href="#原子性问题" aria-hidden="true">#</a> 原子性问题</h4><p>​ 除了 JVM 自身提供的对基本数据类型读写操作的原子性外，可以通过 <strong>synchronized</strong> 和 <strong>Lock</strong> 实现原子性。因为 synchronized 和 Lock 能够保证任一时刻只有一个线程访问该代码块。</p><h4 id="可见性问题" tabindex="-1"><a class="header-anchor" href="#可见性问题" aria-hidden="true">#</a> 可见性问题</h4><p>​ <strong>volatile</strong> 关键字可以保证可见性。当一个共享变量被 volatile 关键字修饰时，它会保证修改的值立即被其他的线程看到，即修改的值立即更新到主存中，当其他线程需要读取时，它会去内存中读取新值。synchronized 和 Lock 也可以保证可见性，因为它们可以保证任一时刻只有一个线程能访问共享资源，并在其释放锁之前将修改的变量刷新到内存中。</p><h4 id="有序性问题" tabindex="-1"><a class="header-anchor" href="#有序性问题" aria-hidden="true">#</a> 有序性问题</h4><p>​ 在Java里面，可以通过 volatile 关键字来保证一定的“有序性”。另外可以通过 synchronized 和 Lock 来保证有序性，很显然，synchronized 和 Lock 保证每个时刻是只有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证来有序性。</p><h3 id="jmm作用" tabindex="-1"><a class="header-anchor" href="#jmm作用" aria-hidden="true">#</a> JMM作用</h3><ol><li><p>JMM提供的语义</p><ul><li><p>使用LOCK#信号、内存屏障实现语言层面的<code>synchronized</code>语义，保证复杂指令块的原子性 ，实现对共享变量的弱一致性保证</p></li><li><p>对共享变量读之间插入<code>加载屏障</code>，在对共享变量写之后插入<code>存储屏障</code>，来实现<code>volatile</code>语义，实现对共享变量的释放一致性和进入一致性保证</p></li><li><p>通过<code>存储屏障</code>，禁止初始化操作不重排到构造器结束之后，来实现<code>final</code>的语义</p></li></ul></li><li><p>通过NATIVA方法屏蔽各硬件平台的差异</p><ul><li><p>不同的硬件底层实现的内存屏障方式不同</p></li><li><p>不同硬件底层的硬件指令不同</p></li></ul></li><li><p>lazy write</p><ul><li><p>通过<code>存储屏障</code>，将写缓冲区中的数据写回主存，保证可见性和有序性</p></li><li><p>通过<code>加载屏障</code>，清空无效化队列，保证可见性和有序性</p></li></ul></li><li><p>禁止重排</p><ul><li><p>通过内存屏障，禁止指令重排，实现<code>as-if -serial</code>语义</p></li><li><p>锁临界区的指令不允许逸出到临界区外</p></li><li><p>内部锁的释放要在内部锁的申请之后执行</p></li><li><p>线程中的任何操作都在start方法之后执行</p></li><li><p>线程中的任何操作都在join方法之前执行</p></li><li><p>同一个volatile变量读和写之间禁止重排</p></li></ul></li></ol><hr><h2 id="内存屏障" tabindex="-1"><a class="header-anchor" href="#内存屏障" aria-hidden="true">#</a> 内存屏障</h2><p>定义：在多核CPU的情况下，因为多核CPU上的指令同时执行，如果涉及到共享变量的修改，这种优化会影响多线程运行的正确性，而<code>内存屏障</code>（memory barrier/memory fence）是硬件层面提供的一系列特殊指令，当CPU处理到这些指定时，会做一些特殊的处理，可以使处理器内的内存状态对其它处理器可见。</p><p>内存屏障就是将 Store Bufferes/Invalid Queue 中的指令写入到内存，从而使得其他访问同一共享内存的线程的可见性。</p><ul><li>Store Memory Barrier(a.k.a. ST, SMB, smp_wmb)是一条告诉处理器在执行这之后的指令之前，应用所有已经在存储缓存（store buffer）中的保存的指令。</li><li>Load Memory Barrier (a.k.a. LD, RMB, smp_rmb)是一条告诉处理器在执行任何的加载前，先应用所有已经在失效队列中的失效操作的指令。</li></ul><h3 id="cpu提供的内存屏障" tabindex="-1"><a class="header-anchor" href="#cpu提供的内存屏障" aria-hidden="true">#</a> CPU提供的内存屏障</h3><p>在X86平台提供了几种主要的内存屏障</p><ul><li><p>lfence - 加载屏障</p><ul><li><p><strong>清空无效化队列</strong>，根据无效化队列中内容的内存地址，将相应处理器上高速缓存中的缓存条件状态置为I，使后续对该地址的读取时，必须发送Read消息。</p></li><li><p>用在读指令前，阻止屏障两边的读指令重排</p></li></ul></li><li><p>sfence - 存储屏障：</p><ul><li><p><strong>冲刷写缓冲器中的内容</strong>，将写缓冲器中内容的更新应用于高速缓存</p></li><li><p>用在写指令之后，阻止屏障两边的写指令重排（执行到该屏障时，将对缓存中的条目打标记，标识这些条目需要在该屏障之前提交，当执行到写操作时，检测到写缓冲器中存在被标记的条目，不管写操作对应的条目状态，即使是E,M也不将写操作的数据回写高速缓存，而是写入写缓冲器的方式，使得屏障之间和屏障之后的指令修改都串行在写缓冲器中，来保证其顺序）</p></li></ul></li><li><p>mfence - 全能屏障</p><ul><li><p>具备ifence和sfence的能力, 实现是通过加载屏障和存储屏障的成对使用，可以保证写缓冲的内容同步到高速缓存，无效化队列的内容应用到高速缓存，然后再根据缓存一致性协议保证共享数据的一致性</p></li><li><p>阻止指令重排序</p></li></ul></li></ul><h3 id="jvm提供的内存屏障" tabindex="-1"><a class="header-anchor" href="#jvm提供的内存屏障" aria-hidden="true">#</a> JVM提供的内存屏障</h3><p>不同硬件实现内存屏障的方式不同，Java 内存模型屏蔽了这些底层硬件平台的差异，由 JVM 来为不同平台生产相应的机器码。JVM中提供了四类内存屏障指令：</p><table><thead><tr><th><strong>指令示例</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>Load1 ; <strong>LoadLoad</strong> ; Load2</td><td>保证load1的读取操作和load2及后续读取操作之前执行</td></tr><tr><td>Store1 ; <strong>StoreStore</strong> ; Store2</td><td>在store2及其后的写操作执行前，保证store1的写操作已刷新到主内存</td></tr><tr><td>Load1 ; <strong>LoadStore</strong> ; Store2</td><td>在store2及其后的写操作执行前，保证load1的读操作已经读取结束</td></tr><tr><td>Store1 ; <strong>StoreLoad</strong> ; Load2</td><td>在store1的写操作已刷新到主内存之后，load2及其后的读操作才能执行</td></tr></tbody></table><p>​ 4个屏障只是Java为了跨平台而设计出来的，实际上根据CPU的不同，对应 CPU 平台上的 JVM 可能可以优化掉一些 屏障，例如LoadLoad、LoadStore和StoreStore是x86上默认就有的行为，在这个平台上写代码时会简化一些开发过程。X86-64下仅支持一种指令重排：StoreLoad ，即读操作可能会重排到写操作前面，同时不同线程的写操作并没有保证全局可见。这个问题用lock或mfence解决，不能靠组合sfence和lfence解决。</p><ul><li><code>LoadLoad</code>，操作序列 Load1, LoadLoad, Load2，用于保证访问 Load2 的读取操作一定不能重排到 Load1 之前。类似于前面说的 <code>Read Barrier</code>，需要先处理 Invalidate Queue 后再读 Load2；</li><li><code>StoreStore</code>，操作序列 Store1, StoreStore, Store2，用于保证 Store1 及其之后写出的数据一定先于 Store2 写出，即别的 CPU 一定先看到 Store1 的数据，再看到 Store2 的数据。可能会有一次 Store Buffer 的刷写，也可能通过所有写操作都放入 Store Buffer 排序来保证；</li><li><code>LoadStore</code>，操作序列 Load1, LoadStore, Store2，用于保证 Store2 及其之后写出的数据被其它 CPU 看到之前，Load1 读取的数据一定先读入缓存。甚至可能 Store2 的操作依赖于 Load1 的当前值。这个 Barrier 的使用场景可能和上一节讲的 Cache 架构模型很难对应，毕竟那是一个极简结构，并且只是一种具体的 Cache 架构，而 JVM 的 Barrier 要足够抽象去应付各种不同的 Cache 架构。如果跳出上一节的 Cache 架构来说，我理解用到这个 Barrier 的场景可能是说某种 CPU 在写 Store2 的时候，认为刷写 Store2 到内存，将其它 CPU 上 Store2 所在 Cache Line 设置为无效的速度要快于从内存读取 Load1，所以做了这种重排。</li><li><code>StoreLoad</code>，操作序列 Store1, StoreLoad, Load2，用于保证 Store1 写出的数据被其它 CPU 看到后才能读取 Load2 的数据到缓存。如果 Store1 和 Load2 操作的是同一个地址，StoreLoad Barrier 需要保证 Load2 不能读 Store Buffer 内的数据，得是从内存上拉取到的某个别的 CPU 修改过的值。<code>StoreLoad</code> 一般会认为是最重的 Barrier 也是能实现其它所有 Barrier 功能的 Barrier。</li></ul>`,101),r={href:"https://link.segmentfault.com/?enc=cWcHdC9Q3hgo6OLbTlqTCg%3D%3D.ipVtAhyRuqVGjuaAeGS6hleJPwIWMFEO0GX5TRRKQ5dQqh5MLrNeFXPJO%2BjeTtZJ0tcYEZ8P9%2FImTA0YYM0DO24nqNvfDM6gMYdGbftUepahU5knT5DP815vcLi5XgCATrqzPR5E%2BiiLzgiIOzSPz12pzWftw9ukdSvu%2FmDGqoqwzE6gu1fY9lyIVf3dMzmlsnAqcz1xFeFzxNr339c6Cm5l7nRWrj1EexvBLewJEwM%3D",target:"_blank",rel:"noopener noreferrer"},u=e('<h4 id="为什么这一堆-barrier-里-storeload-最重" tabindex="-1"><a class="header-anchor" href="#为什么这一堆-barrier-里-storeload-最重" aria-hidden="true">#</a> 为什么这一堆 Barrier 里 <code>StoreLoad</code> 最重？</h4><p>​ 所谓的重实际就是跟内存交互次数，交互越多延迟越大，也就是越重。<code>StoreStore</code>， <code>LoadLoad</code> 两个都不提了，因为它俩要么只限制读，要么只限制写，也即只有一次内存交互。只有 <code>LoadStore</code> 和 <code>StoreLoad</code> 看上去有可能对读写都有限制。但 <code>LoadStore</code> 里实际限制的更多的是读，即 Load 数据进来，它并不对最后的 Store 存出去数据的可见性有要求，只是说 Store 不能重排到 Load 之前。而反观 <code>StoreLoad</code>，它是说不能让 Load 重排到 Store 之前，这么一来得要求在 Load 操作前刷写 Store Buffer 到内存。不去刷 Store Buffer 的话，就可能导致先执行了读取操作，之后再刷 Store Buffer 导致写操作实际被重排到了读之后。而数据一旦刷写出去，别的 CPU 就能看到，看到之后可能就会修改下一步 Load 操作的内存导致 Load 操作的内存所在 Cache Line 无效。如果允许 Load 操作从一个可能被 Invalidate 的 Cache Line 里读数据，则表示 Load 从实际意义上来说被重排到了 Store 之前，因为这个数据可能是 Store 前就在 Cache 中的，相当于读操作提前了。为了避免这种事发生，Store 完成后一定要去处理 Invalidate Queue，去判断自己 Load 操作的内存所在 Cache Line 是否被设置为无效。这么一来为了满足 <code>StoreLoad</code> 的要求，一方面要刷 Store Buffer，一方面要处理 Invalidate Queue，则最差情况下会有两次内存操作，读写分别一次，所以它最重。</p><h4 id="storeload-为什么能实现其它-barrier-的功能" tabindex="-1"><a class="header-anchor" href="#storeload-为什么能实现其它-barrier-的功能" aria-hidden="true">#</a> <code>StoreLoad</code> 为什么能实现其它 Barrier 的功能？</h4><p>​ 这个也是从前一个问题结果能看出来的。<code>StoreLoad</code> 因为对读写操作均有要求，所以它能实现其它 Barrier 的功能。其它 Barrier 都是只对读写之中的一个方面有要求。</p><p>​ 不过这四个 Barrier 只是 Java 为了跨平台而设计出来的，实际上根据 CPU 的不同，对应 CPU 平台上的 JVM 可能可以优化掉一些 Barrier。比如很多 CPU 在读写同一个变量的时候能保证它连续操作的顺序性，那就不用加 Barrier 了。比如 <code>Load x; Load x.field</code> 读 x 再读 x 下面某个 field，如果访问同一个内存 CPU 能保证顺序性，两次读取之间的 Barrier 就不再需要了，根据字节码编译得到的汇编指令中，本来应该插入 Barrier 的地方会被替换为 <code>nop</code>，即空操作。在 x86 上，实际只有 <code>StoreLoad</code> 这一个 Barrier 是有效的，x86 上没有 Invalidate Queue，每次 Store 数据又都会去 Store Buffer 排队，所以 <code>StoreStore</code>， <code>LoadLoad</code> 都不需要。x86 又能保证 Store 操作都会走 Store Buffer 异步刷写，Store 不会被重排到 Load 之前，<code>LoadStore</code> 也是不需要的。只剩下一个 <code>StoreLoad</code> Barrier 在 x86 平台的 JVM 上被使用。</p>',5),k={href:"https://link.segmentfault.com/?enc=3NzQAHAvEye3%2BqKpgiAzNA%3D%3D.4rwm1qnCyyEzylcJu71%2BzFjZOVlJWWyUz8vwOItiIuvfWdtZYjX%2BZ94ujZoNraJoOLA69jnGJqQ4O1lmOKfyBmY%2FQIa11jKqLO31C2Eq97AfWKUp5RSoFzUrulHdWjzsm8XnPxild%2FKlk9BP%2F%2BeM0vVSy8yoBZKY%2FuvWbJDpMMA%3D",target:"_blank",rel:"noopener noreferrer"},h=n("strong",null,"lock",-1),v=n("code",null,"StoreLoad",-1),g=n("code",null,"StoreLoad",-1),m=n("code",null,"lock",-1),b=e(`<p>例子：</p><p>写入相同地址</p><div class="language-javascript line-numbers-mode" data-ext="js"><pre class="language-javascript"><code><span class="token constant">CPU0</span><span class="token operator">:</span>                              <span class="token constant">CPU1</span><span class="token operator">:</span> 
store <span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token operator">&lt;</span><span class="token operator">--</span><span class="token number">1</span>                      
                                   store <span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token operator">&lt;</span><span class="token operator">--</span><span class="token number">2</span>
                                   store <span class="token punctuation">[</span>y<span class="token punctuation">]</span><span class="token operator">&lt;</span><span class="token operator">--</span><span class="token number">2</span>
load  r1<span class="token operator">&lt;</span><span class="token operator">--</span><span class="token punctuation">[</span>x<span class="token punctuation">]</span>                     
load  r2<span class="token operator">&lt;</span><span class="token operator">--</span><span class="token punctuation">[</span>y<span class="token punctuation">]</span>    
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>理论上没有屏障的结果可能是 r1 == 1，r2 == 2，这意味着 CPU1 的两个存储都已经执行（因为我们从 [y] 读取 2），但不知何故 [x] 的旧值仍然存在（因为它已被读取到）。</p><p>写入不同地址</p><div class="language-javascript line-numbers-mode" data-ext="js"><pre class="language-javascript"><code><span class="token constant">CPU0</span><span class="token operator">:</span>                              <span class="token constant">CPU1</span><span class="token operator">:</span> 
store <span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token operator">&lt;</span><span class="token operator">--</span><span class="token number">1</span>                      store <span class="token punctuation">[</span>y<span class="token punctuation">]</span><span class="token operator">&lt;</span><span class="token operator">--</span><span class="token number">1</span>
load  r1<span class="token operator">&lt;</span><span class="token operator">--</span><span class="token punctuation">[</span>y<span class="token punctuation">]</span>                     load r2<span class="token operator">&lt;</span><span class="token operator">--</span><span class="token punctuation">[</span>x<span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这里的地址是不同的，并且由于加载的无序执行，仍然需要一个屏障来防止两个加载都读取旧值的情况。</p><hr><h2 id="volatile" tabindex="-1"><a class="header-anchor" href="#volatile" aria-hidden="true">#</a> volatile</h2><p>​ 禁止指令重排不是禁止所有的重排，只是 <code>volatile</code> 写入不能向前排，读取不能向后排。别的重排还是会允许。另一个是禁止指令重排实际也是为了去满足可见性而附带产生的。所以 <code>volatile</code> 对上述两个特性的维护就能靠 Barrier 来实现。</p><p>重排序分为<strong>编译器重排序</strong>和<strong>处理器重排序</strong>。为来实现 volatile 内存语义，JMM 会分别限制这两种类型的重排序类型。</p><p>下面是JMM针对编译器制定的 volatile 重排序规则表。</p><table><thead><tr><th>第一个操作</th><th>第二个操作：普通读写</th><th>第二个操作：volatile读</th><th>第二个操作：volatile写</th></tr></thead><tbody><tr><td>普通读写</td><td>可以重排</td><td>可以重排</td><td>不可以重排</td></tr><tr><td>volatile读</td><td>不可以重排</td><td>不可以重排</td><td>不可以重排</td></tr><tr><td>volatile写</td><td>可以重排</td><td>不可以重排</td><td>不可以重排</td></tr></tbody></table><p>从上图可以看出：</p><ul><li>当第二个操作是 volatile 写时，不管第一个操作是什么，都不能重排序。这个规则确保了 volatile 写之前的操作不会被编译器重排序到 volatile 写之后。</li><li>当第一个操作是 volatile 读时，不管第二个操作是什么，都不能重排序。这个规则确保了 volatile 读之后的操作不会被编译器重排序到 volatie 读之前。</li><li>当第一个操作是 volatile 写，第二个操作是 volatile 读或写时，不能重排序。</li></ul><p>为了实现 volatile 的内存语义，编译在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能。为此，JMM 采取保守策略。下面是基于保守策略的JMM内存屏障插入策略。</p><ul><li>在每个volatile写操作的前面插入一个StoreStore屏障；</li><li>在每个volatile写操作的后面插入一个StoreLoad屏障；</li><li>在每个volatile读操作的后面插入一个LoadLoad屏障；</li><li>在每个volatile读操作的后面插入一个LoadStore屏障；</li></ul><p>上述内存屏障插入策略非常保守，但它可以保证在任一处理器平台，任意的程序中都能得到正确的 volatile 内存语义。</p><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/image-20240212110722669.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/image-20240212110749729.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure>`,20),f=n("code",null,"volatile",-1),y=n("strong",null,[a("变量是不是 "),n("code",null,"volatile"),a(" 声明的，生成的字节码都是一样的")],-1),S=n("code",null,"volatile",-1),C=n("code",null,"access_flags",-1),M={href:"https://link.segmentfault.com/?enc=cn53i1kcvgkZ63%2FIsZRoew%3D%3D.fKoeR55R8vUBDqunGnfiRr5CBoabJgIKvUVbGowykebhXFxCgyo628rnWnEI7zDwWygeGEgI4jTuH1MqLWhRIQ%3D%3D",target:"_blank",rel:"noopener noreferrer"},x=n("code",null,"volatile",-1),L=n("code",null,"volatile",-1),w=n("code",null,"getfield",-1),P=n("code",null,"putfield",-1),U=n("code",null,"volatile",-1),B=e(`<p>从CPU指令角度来看volatile关键字的实现 ，其实是使用到的<strong>内存屏障</strong>，通过内存屏障保证在<strong>共享变量写的时候冲刷处理器</strong>，<strong>共享变量读的时候刷新处理器缓存</strong>。</p><blockquote><ul><li>处理器对<strong>共享变量</strong>所做的更新操作，从写缓冲器中写入处理器的高速缓存或者主内存中，这个动作被称为<strong>冲刷处理器缓存</strong></li><li>处理器读取<strong>共享变量</strong>时，如果其它处理器更新了该值，那么处理器要从其它处理器的高速缓存或者主内存中进行同步相应的变量值到本缓存，这个动作被称为<strong>刷新处理器缓存</strong></li></ul></blockquote><h3 id="单例模式" tabindex="-1"><a class="header-anchor" href="#单例模式" aria-hidden="true">#</a> 单例模式</h3><div class="language-java line-numbers-mode" data-ext="java"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">Singleton</span> <span class="token punctuation">{</span>
   <span class="token keyword">private</span> <span class="token keyword">static</span> <span class="token keyword">volatile</span> <span class="token class-name">Singleton</span> instance <span class="token operator">=</span> <span class="token keyword">null</span><span class="token punctuation">;</span>
   <span class="token keyword">private</span> <span class="token class-name">Singleton</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
 
   <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token class-name">Singleton</span> <span class="token function">getInstance</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
   <span class="token keyword">if</span> <span class="token punctuation">(</span>instance <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
     <span class="token keyword">synchronized</span><span class="token punctuation">(</span><span class="token class-name">Singleton</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
       <span class="token keyword">if</span> <span class="token punctuation">(</span>instance <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span>
         instance <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Singleton</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
     <span class="token punctuation">}</span>
   <span class="token punctuation">}</span>
   <span class="token keyword">return</span> instance<span class="token punctuation">;</span>
   <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p>singleton = new Singleton()这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情。</p><p>1. 给 singleton 分配内存</p><p>2. 调用 Singleton 的构造函数来初始化成员变量，形成实例</p><p>3. 将singleton对象指向分配的内存空间（执行完这步 singleton才是非 null了）</p><p>​ <strong>注意：volatile阻止的不是singleton = new Singleton()这句话内部[1-2-3]的指令重排，而是保证了在一个写操作（[1-2-3]）完成之前，不会调用读操作(if (instance == null))</strong>。即happens-before</p></blockquote><h4 id="spring生成bean的双重检查锁源码中为什么没有添加volatile" tabindex="-1"><a class="header-anchor" href="#spring生成bean的双重检查锁源码中为什么没有添加volatile" aria-hidden="true">#</a> spring生成bean的双重检查锁源码中为什么没有添加volatile</h4><div class="language-java line-numbers-mode" data-ext="java"><pre class="language-java"><code><span class="token comment">//经典的双重检查锁中会使用volatile来修饰被synchronized锁定的对象以防止代码重排这里为什么不需要。</span>
<span class="token keyword">private</span> <span class="token keyword">final</span> <span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Object</span><span class="token punctuation">&gt;</span></span> singletonObjects <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ConcurrentHashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token number">11256</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">protected</span> <span class="token class-name">Object</span> <span class="token function">getSingleton</span><span class="token punctuation">(</span><span class="token class-name">String</span> beanName<span class="token punctuation">,</span> <span class="token keyword">boolean</span> allowEarlyReference<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token class-name">Object</span> singletonObject <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>singletonObjects<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>beanName<span class="token punctuation">)</span><span class="token punctuation">;</span>
	<span class="token keyword">if</span> <span class="token punctuation">(</span>singletonObject <span class="token operator">==</span> <span class="token keyword">null</span> <span class="token operator">&amp;&amp;</span> <span class="token function">isSingletonCurrentlyInCreation</span><span class="token punctuation">(</span>beanName<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
		<span class="token keyword">synchronized</span> <span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>singletonObjects<span class="token punctuation">)</span> <span class="token punctuation">{</span>
			singletonObject <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>earlySingletonObjects<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>beanName<span class="token punctuation">)</span><span class="token punctuation">;</span>
			<span class="token keyword">if</span> <span class="token punctuation">(</span>singletonObject <span class="token operator">==</span> <span class="token keyword">null</span> <span class="token operator">&amp;&amp;</span> allowEarlyReference<span class="token punctuation">)</span> <span class="token punctuation">{</span>
				<span class="token class-name">ObjectFactory</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token operator">?</span><span class="token punctuation">&gt;</span></span> singletonFactory <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>singletonFactories<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span>beanName<span class="token punctuation">)</span><span class="token punctuation">;</span>
				<span class="token keyword">if</span> <span class="token punctuation">(</span>singletonFactory <span class="token operator">!=</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
					singletonObject <span class="token operator">=</span> singletonFactory<span class="token punctuation">.</span><span class="token function">getObject</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
					<span class="token keyword">this</span><span class="token punctuation">.</span>earlySingletonObjects<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>beanName<span class="token punctuation">,</span> singletonObject<span class="token punctuation">)</span><span class="token punctuation">;</span>
					<span class="token keyword">this</span><span class="token punctuation">.</span>singletonFactories<span class="token punctuation">.</span><span class="token function">remove</span><span class="token punctuation">(</span>beanName<span class="token punctuation">)</span><span class="token punctuation">;</span>
				<span class="token punctuation">}</span>
			<span class="token punctuation">}</span>
		<span class="token punctuation">}</span>
	<span class="token punctuation">}</span>
	<span class="token keyword">return</span> singletonObject<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>从 spring 初始化到其它线程获取对象，大体步骤是这样子：</p><table><thead><tr><th>步骤</th><th>线程1</th><th>线程2</th></tr></thead><tbody><tr><td>1</td><td>初始化单例对象</td><td></td></tr><tr><td>2</td><td>把单例对象放到 singletonObjects</td><td></td></tr><tr><td>3</td><td></td><td>从 singletonObjects 获取单例对象</td></tr><tr><td>4</td><td></td><td>使用单例对象</td></tr></tbody></table><p>如果能证明步骤2执行完后，步骤3一定能拿到单例对象（内存可见性），并且步骤1先发生于步骤4（步骤4不会拿到未初始化好的对象），那么就是线程安全的。</p><p>下面用 happen-before 原则简单证明一下。</p><ol><li>程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作；</li><li>锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作；</li><li>volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作；</li><li>传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C；</li><li>线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作；</li><li>线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生；</li><li>线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行；</li><li>对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始。</li></ol><p>根据程序次序规则，可以证明步骤1先发生于步骤2，步骤3先发生于步骤4；</p><p>根据volatile变量规则，因为 singletonObjects 是一个 ConcurrentHashMap，其内部使用 volatile 关键字修饰 value，所以可以证明步骤2先发生于步骤3；</p><p>最后根据传递规则，可以证明步骤1先发生于步骤4，证明完毕。</p><p>附<code>ConcurrentHashMap</code>源码：</p><div class="language-java line-numbers-mode" data-ext="java"><pre class="language-java"><code><span class="token keyword">static</span> <span class="token keyword">class</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token keyword">implements</span> <span class="token class-name">Map<span class="token punctuation">.</span>Entry</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span>
    <span class="token keyword">final</span> <span class="token keyword">int</span> hash<span class="token punctuation">;</span>
    <span class="token keyword">final</span> <span class="token class-name">K</span> key<span class="token punctuation">;</span>
    <span class="token keyword">volatile</span> <span class="token class-name">V</span> val<span class="token punctuation">;</span>
    <span class="token keyword">volatile</span> <span class="token class-name">Node</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">K</span><span class="token punctuation">,</span><span class="token class-name">V</span><span class="token punctuation">&gt;</span></span> next<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><hr><h2 id="思考" tabindex="-1"><a class="header-anchor" href="#思考" aria-hidden="true">#</a> 思考</h2><h3 id="jmm、volatile与mesi的关系" tabindex="-1"><a class="header-anchor" href="#jmm、volatile与mesi的关系" aria-hidden="true">#</a> JMM、volatile与MESI的关系</h3><p>总结来说，<code>volatile</code> 可见性包括两个方面：</p><ol><li>写入的 <code>volatile</code> 变量在写完之后能被别的 CPU 在下一次读取中读取到；</li><li>写入 <code>volatile</code> 变量之前的操作在别的 CPU 看到 <code>volatile</code> 的最新值后一定也能被看到；</li></ol><p>对于第一个方面，主要通过：</p><ol><li>读取 <code>volatile</code> 变量不能使用寄存器，每次读取都要去内存拿</li><li>禁止读 <code>volatile</code> 变量后续操作被重排到读 <code>volatile</code> 之前</li></ol><p>对于第二个方面，主要是通过写 <code>volatile</code> 变量时的 Barrier 保证写 <code>volatile</code> 之前的操作先于写 <code>volatile</code> 变量之前发生。</p><p>最后还一个特殊的，如果能用到 <code>StoreLoad</code> Barrier，写 <code>volatile</code> 后一般会触发 Store Buffer 的刷写，所以写操作能「立即」被别的 CPU 看到。</p><p>一般提到 <code>volatile</code> 可见性怎么实现，最常听到的解释是「写入数据之后加一个写 Barrier 去刷缓存到主存，读数据之前加入 Barrier 去强制从主存读」。</p><p>​ 从前面对 JMM 的介绍能看到，至少从 JMM 的角度来说，这个说法是不够准确的。一方面 Barrier 按说加在写 <code>volatile</code> 变量之前，不该之后加 Barrier。而读 <code>volatile</code> 是在之后会加 Barrier，而不在之前。另一方面关于 「刷缓存」的表述也不够准确，即使是 <code>StoreLoad</code> Barrier 刷的也是 Store Buffer 到缓存里，而不是缓存向主存去刷。如果待写入的目标内存在当前 CPU Cache，即使触发 Store Buffer 刷写也是写数据到 Cache，并不会触发 Cache 的 Writeback 即向内存做同步的事情，同步主存也没有意义因为别的 CPU 并不一定关心这个值；同理，即使读 <code>volatile</code> 变量后有 Barrier 的存在，如果目标内存在当前 CPU Cache 且处于 Valid 状态，那读取操作就立即从 Cache 读，并不会真的再去内存拉一遍数据。</p><p>​ 需要补充的是无论是<code>volatile</code> 还是普通变量在读写操作本身方面完全是一样的，即读写操作都交给 Cache，Cache 通过 MESI 及其变种协议去做缓存一致性维护。这两种变量的区别就只在于 Barrier 的使用上。</p><blockquote><p>​ volatile写后有StoreLoad屏障，会将Store Buffer的数据刷回高速缓存，然后将其他CPU的Invalid Queue清空，这样当前写的CPU MESI状态为M，别的CPU状态为I，再来读取时会读取当前M状态的别的CPU中的值，即达到volatile的语义效果。这也就是JMM中对<strong>一个 volatile 变量的写操作先行发生于后面对这个变量的读操作</strong>的<code>happens-before</code>原则。</p></blockquote><h3 id="volatile读取操作是free的吗" tabindex="-1"><a class="header-anchor" href="#volatile读取操作是free的吗" aria-hidden="true">#</a> volatile读取操作是Free的吗</h3><p>​ 在 x86 下因为除了 <code>StoreLoad</code> 之外其它 Barrier 都是空操作，但是读 <code>volatile</code> 变量并不是完全无开销，一方面 Java 的编译器还是会遵照 JMM 要求在本该加入 Barrier 的汇编指令处填入 <code>nop</code>，这会阻碍 Java 编译器的一些优化措施。比如本来能进行指令重排的不敢进行指令重排等。另外因为访问的变量被声明为 <code>volatile</code>，每次读取它都得从内存( 或 Cache ) 要，而不能把 <code>volatile</code> 变量放入寄存器反复使用。这也降低了访问变量的性能。</p><p>​ 理想情况下对 <code>volatile</code> 字段的使用应当多读少写，并且尽量只有一个线程进行写操作。不过读 <code>volatile</code> 相对读普通变量来说也有开销存在，只是一般不是特别重。</p><hr><h3 id="在多个线程共享变量的情况下-mesi协议已经能够保障一个线程对共享变量的更新对其它处理器上运行的线程来说是可见的-既然如此-java中的可见问题为何会存在" tabindex="-1"><a class="header-anchor" href="#在多个线程共享变量的情况下-mesi协议已经能够保障一个线程对共享变量的更新对其它处理器上运行的线程来说是可见的-既然如此-java中的可见问题为何会存在" aria-hidden="true">#</a> 在多个线程共享变量的情况下，MESI协议已经能够保障一个线程对共享变量的更新对其它处理器上运行的线程来说是可见的；既然如此，JAVA中的可见问题为何会存在？</h3><blockquote><p><strong>MESI 解决数据一致性（Data Conherence）问题，而 volatile 解决顺序一致性（Sequential Consistency）问题</strong></p><p>顺序一致性讨论的是对多个数据的多次操作顺序在整个系统上的一致性。在并发编程中，存在 3 种指令顺序：</p><ul><li><strong>编码顺序（Progrom Order）：</strong> 指源码中指令的编写顺序，是程序员视角看到的指令顺序，不一定是实际执行的顺序；</li><li><strong>执行顺序（Memory Order）：</strong> 指单个线程或处理器上实际执行的指令顺序；</li><li><strong>全局执行顺序（Global Memory Order）：</strong> 每个线程或处理器上看到的系统整体的指令顺序，在弱顺序一致性模型下，每个线程看到的全局执行顺序可能是不同的。</li></ul><p>顺序一致性模型是计算机科学家提出的一种理想参考模型，为程序员描述了一个极强的全局执行顺序一致性，由 2 个特性组成：</p><ul><li><strong>特性 1 - 执行顺序与编码顺序一致：</strong> 保证每个线程中指令的执行顺序与编码顺序一致；</li><li><strong>特性 2 - 全局执行顺序一致：</strong> 保证每个指令的结果会同步到主内存和各个线程的工作内存上，使得每个线程上看到的全局执行顺序一致。</li></ul><p>虽然顺序一致性模型对程序员非常友好，但是对编译器和处理器却不见得喜闻乐见。如果程序完全按照顺序一致性模型来实现，那么处理器和编译器的很多重排序优化都要被禁止，这对程序的 <strong>“并行度”</strong> 会有影响。例如：</p><ul><li><strong>1、重排序问题：</strong> 编译器和处理器不能重排列没有依赖关系的指令；</li><li><strong>2、内存可见性问题：</strong> CPU 不能使用写回策略，也不能使用写缓冲区和失效队列机制。其实，从内存的视角看也是指令重排问题。</li></ul><p>所以，在 Java 虚拟机和处理器实现中，实际上使用的是弱顺序一致性模型：</p><ul><li><strong>特性 1 - 不要求执行顺序与编码顺序一致：</strong> 不要求单线程的执行顺序与编码顺序一致，只要求执行结果与强顺序执行的结果一致，而指令是否真的按编码顺序执行并不关心。因为结果不变，从程序员的视角看程序就是按编码顺序执行的假象；</li><li><strong>特性 2 - 不要求全局执行顺序一致：</strong> 允许每个线程看到的全局执行顺序不一致，甚至允许看不到其他线程已执行指令的结果。</li></ul><p>​ <strong>再举个多线程的例子：</strong> 我们在 ChangeThread 线程修改变量，在主线程观察变量的值。在弱顺序一致性模型下，允许 ChangeThread 线程 A 指令的执行结果不及时同步到主线程，在主线程看来就像没执行过 A 指令。</p><p><strong>这个问题我们一般会理解为内存可见性问题，其实我们可以统一理解为顺序一致性问题。</strong></p><div class="language-java line-numbers-mode" data-ext="java"><pre class="language-java"><code><span class="token comment">// 线程 A</span>
a <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">;</span> <span class="token comment">// A1</span>
flag <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment">// A2</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-java line-numbers-mode" data-ext="java"><pre class="language-java"><code><span class="token comment">// 线程 B</span>
<span class="token keyword">while</span> <span class="token punctuation">(</span>flag<span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment">// B1</span>
    <span class="token keyword">return</span> a <span class="token operator">*</span> a<span class="token punctuation">;</span> <span class="token comment">// B2</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>情况 1：由于 A1 和 A2 没有数据依赖性，所以编译器或处理器可能会重排序 A1 和 A2 的顺序。在 A2 将 <code>flag</code> 改为 <code>true</code> 后，B1 读取到 <code>flag</code> 条件为真，并且进入分支计算 B2 结果，但 A1 还未写入，计算结果是 <code>0</code>。此时，程序的运行结果就被重排列破坏了。</p><p>情况 2：另一种可能，由于 B1 和 B2 没有数据依赖性，CPU 可能用分支预测技术提前执行 B2，但 A1 还未写入，计算结果还是 <code>0</code>。此时，程序的运行结果就被重排列破坏了。</p><p>​ 即使不考虑写缓冲区或失效队列，MESI 也只是解决数据一致性问题，并不能解决顺序一致性问题。在实际的计算机系统中，为了提高程序的性能，Java 虚拟机和处理器会使用弱顺序一致性模型。</p><p>​ 在单线程程序下，弱顺序一致性与强顺序一致性的执行结果完全相同。但在多线程程序下，重排序问题和可见性问题会导致各个线程看到的全局执行顺序不一致，使得程序的执行结果与预期不一致。</p><p>​ 为了纠正弱顺序一致性的影响，编译器和处理器都提供了 <strong>“内存屏障指令”</strong> 来保证程序关键节点的执行顺序能够与程序员的预期一致。在高级语言中，我们不会直接使用内存屏障，而是使用更高级的语法，即 synchronized、volatile、final、CAS 等语法。</p></blockquote><hr><h3 id="既然cpu有缓存一致性协议-mesi-为什么jmm还需要volatile关键字" tabindex="-1"><a class="header-anchor" href="#既然cpu有缓存一致性协议-mesi-为什么jmm还需要volatile关键字" aria-hidden="true">#</a> 既然CPU有缓存一致性协议（MESI），为什么JMM还需要volatile关键字？</h3><p><strong>volatile</strong>是java语言层面给出的保证，<strong>MSEI协议</strong>是多核cpu保证cache一致性的一种方法，中间隔的还很远，我们可以先来做几个假设：</p><ol><li>回到远古时候，那个时候cpu只有单核，或者是多核但是保证sequence consistency，当然也无所谓有没有MESI协议了。那这个时候，我们需要java语言层面的volatile的支持吗？</li></ol><blockquote><p>当然是需要的，因为在语言层面编译器和虚拟机为了做性能优化，可能会存在<strong>指令重排</strong>的可能，而volatile给我们提供了一种能力，我们可以告诉编译器，什么可以重排，什么不可以。</p></blockquote><ol start="2"><li>那好，假设更进一步，假设java语言层面不会对指令做任何的优化重排，那在多核cpu的场景下，我们还需要volatile关键字吗？</li></ol><blockquote><p>答案仍然是需要的。因为 MESI只是保证了多核cpu的独占cache之间的一致性，但是cpu的并不是直接把数据写入L1 cache的，中间还可能有store buffer。有些arm和power架构的cpu还可能有load buffer或者invalid queue等等。因此，有MESI协议远远不够。</p></blockquote><ol start="3"><li>再接着，让我们再做一个更大胆的假设。假设cpu中这类store buffer/invalid queue等等都不存在了，cpu是数据是直接写入cache的，读取也是直接从cache读的，那还需要volatile关键字吗？</li></ol><blockquote><p>你猜的没错，还需要的。原因就在这个“一致性”上。consistency和coherence都可以被翻译为一致性，<strong>但是MSEI协议这里保证的仅仅coherence</strong>而不是consistency。那consistency和cohence有什么区别呢？</p></blockquote><blockquote><p>下面取自wiki的一段话： Coherence deals with maintaining a global order in which writes to a single location or single variable are seen by all processors. Consistency deals with the ordering of operations to multiple locations with respect to all processors.</p></blockquote><p>因此，<strong>MESI协议最多只是保证了对于一个变量，在多个核上的读写顺序，对于多个变量而言是没有任何保证的</strong>。很遗憾，还是需要volatile～～</p><ol start="4"><li>好的，到了现在这步，我们再来做最后一个假设，假设cpu写cache都是按照指令顺序fifo写的，那现在可以抛弃volatile了吧？你觉得呢？</li></ol><blockquote><p>那肯定不行啊！因为对于arm和power这个weak consistency的架构的cpu来说，它们只会保证指令之间有比如控制依赖，数据依赖，地址依赖等等依赖关系的指令间提交的先后顺序，而对于完全没有依赖关系的指令，比如<code>x=1;y=2</code>，它们是不会保证执行提交的顺序的，除非你使用了volatile，java把volatile编译成arm和power能够识别的barrier指令，这个时候才是按顺序的。</p></blockquote><p><strong>最后总结，答案就是：还需要～～</strong></p><hr>`,51);function j(I,A){const s=i("ExternalLinkIcon");return l(),c("div",null,[d,n("p",null,[a("​ 对上面四种 Barrier 解释最好的是来自这里："),n("a",r,[a("jdk/MemoryBarriers.java at 6bab0f539fba8fb441697846347597b4a0ade428 · openjdk/jdk · GitHub"),t(s)]),a("，感觉比 JSR-133 Cookbook 里的还要细一点。")]),u,n("p",null,[a("​ x86 上怎么使用 Barrier 的说明可以在 openjdk 的代码中看到，在这里"),n("a",k,[a("src/hotspot/cpu/x86/assembler_x86.hpp"),t(s)]),a("。可以看到 x86 下使用的是 "),h,a("来实现 "),v,a("，并且只有 "),g,a(" 有效果。在这个代码注释中还大致介绍了使用 "),m,a(" 的原因。")]),b,n("p",null,[a("​ "),f,a(" 对代码生成的字节码本身没有影响，即 Java Method 生成的字节码无论里面操作的"),y,a("。"),S,a(" 在字节码层面影响的是 Class 内 Field 的 "),C,a("(参看 "),n("a",M,[a("Java 11 The Java Virtual Machine Specification"),t(s)]),a(" 的 4.5 节)，可以理解为当看到一个成员变量被声明为 "),x,a("，Java 编译器就在这个成员变量上打个标记记录它是 "),L,a(" 的。JVM 在将字节码编译为汇编时，如果碰见比如 "),w,a(", "),P,a(" 这些字节码，并且发现操作的是带着 "),U,a(" 标记的成员变量，就会在汇编指令中根据 JMM 要求插入对应的 Barrier。")]),B])}const _=o(p,[["render",j],["__file","缓存.html.vue"]]);export{_ as default};
