import{_ as n,H as l,X as o,Y as r,Z as e,a0 as i,a1 as t,$ as s}from"./framework-47f15ee6.js";const d={},c=s(`<h1 id="redis" tabindex="-1"><a class="header-anchor" href="#redis" aria-hidden="true">#</a> Redis</h1><p>[toc]</p><h2 id="概述" tabindex="-1"><a class="header-anchor" href="#概述" aria-hidden="true">#</a> 概述</h2><h3 id="redis为什么快" tabindex="-1"><a class="header-anchor" href="#redis为什么快" aria-hidden="true">#</a> Redis为什么快</h3><ol><li>Redis是纯内存数据库，一般都是简单的存取操作，线程占用的时间很多，时间的花费主要集中在IO上，所以读取速度快。</li><li>Redis使用的是非阻塞IO、IO多路复用，使用了单线程来轮询描述符，将数据库的开、关、读、写都转换成了事件，减少了线程切换时上下文的切换和竞争。</li><li>Redis采用了单线程的模型，保证了每个操作的原子性，也减少了线程的上下文切换和竞争。</li><li>Redis避免了多线程的锁的消耗。</li><li>Redis采用自己实现的事件分离器，效率比较高，内部采用非阻塞的执行方式，吞吐能力比较大。</li></ol><h3 id="应用场景" tabindex="-1"><a class="header-anchor" href="#应用场景" aria-hidden="true">#</a> 应用场景</h3><ol><li>数据缓存</li></ol><p>​ 经典的场景，现在几乎是所有中大型网站都在用的提升手段，合理地利用缓存能够提升网站访问速度，主要是因为Redis读写性能优异。</p><ol start="2"><li>限时业务的运用</li></ol><p>​ redis中可以使用expire命令设置一个键的生存时间，到时间后redis会删除它。利用这一特性可以运用在限时的优惠活动信息、手机验证码等业务场景。</p><ol start="3"><li>计数器相关问题</li></ol><p>​ <code>redis</code>由于<code>incrby</code>命令可以实现原子性的递增，所以可以运用于高并发的秒杀活动、分布式序列号的生成、具体业务还体现在比如限制一个手机号发多少条短信、一个接口一分钟限制多少请求、一个接口一天限制调用多少次等等。</p><ol start="4"><li>排行榜</li></ol><p>可以借助Redis提供的有序集合（<code>sorted set</code>）能力实现排行榜的功能</p><ol start="5"><li>分布式</li></ol><p>在分布式架构中，为了保证并发访问时操作的原子性，可以利用Redis来实现分布式锁的功能</p><ol start="6"><li>点赞、好友等相互关系的存储</li></ol><p>Redis 利用集合的一些命令，比如求交集、并集、差集等。</p><p>在微博应用中，每个用户关注的人存在一个集合中，就很容易实现求两个人的共同好友功能。</p><ol start="7"><li>简单队列</li></ol><p>由于Redis有list push和list pop这样的命令，所以能够很方便的执行队列操作。</p><hr><h2 id="线程模型" tabindex="-1"><a class="header-anchor" href="#线程模型" aria-hidden="true">#</a> 线程模型</h2><p>Redis是基于Reactor网络模型的单线程模型</p><h3 id="单线程" tabindex="-1"><a class="header-anchor" href="#单线程" aria-hidden="true">#</a> 单线程</h3><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/redis-io-multiplexing.png" alt="redis-io-multiplexing" tabindex="0" loading="lazy"><figcaption>redis-io-multiplexing</figcaption></figure><p>​ Redis 作为一个内存服务器，它需要处理很多来自外部的网络请求，它使用 I/O 多路复用机制同时监听多个文件描述符的可读和可写状态，一旦收到网络请求就会在内存中快速处理，由于绝大多数的操作都是纯内存的，所以处理的速度会非常地快。</p><p>Redis 从一开始就选择使用单线程模型处理来自客户端的绝大多数网络请求，这种考虑其实是多方面的，最重要的几个原因如下：</p><ol><li>使用单线程模型能带来更好的可维护性，方便开发和调试；</li><li>使用单线程模型也能并发的处理客户端的请求；</li><li>Redis 服务中运行的绝大多数操作的性能瓶颈都不是 CPU；</li></ol><p>上述三个原因中的最后一个是最终使用单线程模型的决定性因素，其他的两个原因都是使用单线程模型额外带来的好处。</p><hr><h3 id="事件驱动模型" tabindex="-1"><a class="header-anchor" href="#事件驱动模型" aria-hidden="true">#</a> 事件驱动模型</h3><p>Redis 是一个事件驱动的内存数据库，服务器需要处理两种类型的事件。</p><h4 id="文件事件" tabindex="-1"><a class="header-anchor" href="#文件事件" aria-hidden="true">#</a> 文件事件</h4><p>​ Redis 服务器通过 socket 实现与客户端（或其他redis服务器）的交互，文件事件就是服务器对 socket 操作的抽象。 Redis服务器，通过监听这些 socket 产生的文件事件并处理这些事件，实现对客户端调用的响应。</p><h5 id="reactor" tabindex="-1"><a class="header-anchor" href="#reactor" aria-hidden="true">#</a> Reactor</h5><p>Redis 基于 Reactor 模式开发了自己的事件处理器。</p><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/Reactor.jpg" alt="reactor" tabindex="0" loading="lazy"><figcaption>reactor</figcaption></figure><p>​ <strong>I/O多路复用模块</strong>会监听多个 FD ，当这些FD产生，accept，read，write 或 close 的文件事件。会向<strong>文件事件分发器</strong>(dispatcher)传送事件。文件事件分发器（dispatcher）在收到事件之后，会根据事件的类型将事件分发给对应的 handler。</p><p>​ Redis 的 I/O 多路复用模块，其实是封装了操作系统提供的 select，epoll，avport 和 kqueue 这些基础函数。向上层提供了一个统一的接口，屏蔽了底层实现的细节。</p><blockquote><p>epoll的整个过程。</p><ol><li><code>epoll_create</code>创建了<code>eventpoll</code>实例，并对其中的就绪队列<code>rdllist</code>、等待队列<code>wq</code>以及红黑树<code>rbr</code>进行了初始化；</li><li><code>epoll_ctl</code>将我们感兴趣的socket封装成<code>epitem</code>对象加入红黑树，除此之外，还封装了socket的<code>sk_wq</code>等待队列项，里边保存了socket就绪之后的函数回调，也就是<code>ep_poll_callback</code>；</li><li><code>epoll_wait</code>检查<code>eventpoll</code>的就绪队列是不是有就绪的socket，有的话直接返回；否则就封装一个<code>eventpoll</code>的等待队列项，里边保存了当前的用户进程信息以及另一个回调函数<code>default_wake_function</code>，然后把当前进程投入睡眠；</li><li>直到数据到达，内核线程找到就绪的socket，先调用<code>ep_poll_callback</code>，然后<code>ep_poll_callback</code>又调用<code>default_wake_function</code>，最终唤醒<code>eventpoll</code>等待队列中保存的进程，处理<code>rdllist</code>中的就绪fd；</li><li>epoll结束！</li></ol></blockquote><p>处理一个简单命令涉及到的三个处理器：</p><ul><li>acceptTcpHandler 连接应答处理器，负责处理连接相关的事件，当有client 连接到Redis的时候们就会产生 AE_READABLE 事件。引发它执行。</li><li>readQueryFromClinet 命令请求处理器，负责读取通过 sokect 发送来的命令。</li><li>sendReplyToClient 命令回复处理器，当Redis处理完命令，就会产生 AE_WRITEABLE 事件，将数据回复给 client。</li></ul><hr><h4 id="时间事件" tabindex="-1"><a class="header-anchor" href="#时间事件" aria-hidden="true">#</a> 时间事件</h4><p>Reids 有很多操作需要在给定的时间点进行处理，时间事件就是对这类定时任务的抽象。</p><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/timeEvent.jpg" alt="timeEvent" tabindex="0" loading="lazy"><figcaption>timeEvent</figcaption></figure><p>注意这是一个按照id倒序排列的链表，并没有按照事件顺序排序。</p><p>Redis 使用processTimeEvent函数处理所有的时间事件，我们整理一下执行思路：</p><ol><li>记录最新一次执行这个函数的时间，用于处理系统时间被修改产生的问题。</li><li>遍历链表找出所有 when_sec 和 when_ms 小于现在时间的事件。</li><li>执行事件对应的处理函数。</li><li>检查事件类型，如果是周期事件则刷新该事件下一次的执行事件。</li><li>否则从列表中删除事件。</li></ol><p>综合调度器(aeProcessEvents)是 Redis 统一处理所有事件的地方。我们梳理一下这个函数的简单逻辑：</p><div class="language-c line-numbers-mode" data-ext="c"><pre class="language-c"><code><span class="token comment">// 1. 获取离当前时间最近的时间事件</span>
shortest <span class="token operator">=</span> <span class="token function">aeSearchNearestTimer</span><span class="token punctuation">(</span>eventLoop<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 2. 获取间隔时间</span>
timeval <span class="token operator">=</span> shortest <span class="token operator">-</span> nowTime<span class="token punctuation">;</span>

<span class="token comment">// 如果timeval 小于 0，说明已经有需要执行的时间事件了。</span>
<span class="token keyword">if</span><span class="token punctuation">(</span>timeval <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
    timeval <span class="token operator">=</span> <span class="token number">0</span>
<span class="token punctuation">}</span>

<span class="token comment">// 3. 在 timeval 时间内，取出文件事件。</span>
numevents <span class="token operator">=</span> <span class="token function">aeApiPoll</span><span class="token punctuation">(</span>eventLoop<span class="token punctuation">,</span> timeval<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 4.根据文件事件的类型指定不同的文件处理器</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span>AE_READABLE<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token comment">// 读事件</span>
    <span class="token function">rfileProc</span><span class="token punctuation">(</span>eventLoop<span class="token punctuation">,</span>fd<span class="token punctuation">,</span>fe<span class="token operator">-&gt;</span>clientData<span class="token punctuation">,</span>mask<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
    <span class="token comment">// 写事件</span>
<span class="token keyword">if</span> <span class="token punctuation">(</span>AE_WRITABLE<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token function">wfileProc</span><span class="token punctuation">(</span>eventLoop<span class="token punctuation">,</span>fd<span class="token punctuation">,</span>fe<span class="token operator">-&gt;</span>clientData<span class="token punctuation">,</span>mask<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>Redis 的 main() 方法执行了一些配置和准备以后就调用 <code>eaMain()</code> 方法。</li><li><code>eaMain()</code> while(true) 的调用 <code>aeProcessEvents()</code>。</li></ul><p>所以我们说 Redis 是一个事件驱动的程序，期间我们发现，Redis 没有 fork 过任何线程。所以也可以说 Redis 是一个基于事件驱动的单线程应用。</p><hr><h3 id="多线程使用" tabindex="-1"><a class="header-anchor" href="#多线程使用" aria-hidden="true">#</a> 多线程使用</h3><h4 id="异步删除" tabindex="-1"><a class="header-anchor" href="#异步删除" aria-hidden="true">#</a> 异步删除</h4><p>​ Redis 在最新的几个版本中加入了一些可以被其他线程异步处理的删除操作，也就是 <code>UNLINK</code>、<code>FLUSHALL ASYNC</code> 和 <code>FLUSHDB ASYNC</code>。我们可以在 Redis 在中使用 <code>DEL</code> 命令来删除一个键对应的值，如果待删除的键值对占用了较小的内存空间，那么哪怕是<strong>同步地</strong>删除这些键值对也不会消耗太多的时间。</p><p>​ 但是对于 Redis 中的一些超大键值对，几十 MB 或者几百 MB 的数据并不能在几毫秒的时间内处理完，Redis 可能会需要在释放内存空间上消耗较多的时间，这些操作就会阻塞待处理的任务，影响 Redis 服务处理请求的 <code>PCT99</code> 和可用性。然而释放内存空间的工作其实可以由后台线程异步进行处理，这也就是 <code>UNLINK</code> 命令的实现原理，它只会将键从元数据中删除，真正的删除操作会在后台异步执行。</p><h4 id="处理多请求解析与响应" tabindex="-1"><a class="header-anchor" href="#处理多请求解析与响应" aria-hidden="true">#</a> 处理多请求解析与响应</h4><p>​ I/O 多路复用的主要作用是让我们可以使用一个线程来监控多个连接是否可读或者可写，但是从网络另一头发的数据包需要<strong>先解序列化成 Redis 内部其他模块可以理解的命令</strong>，<strong>这个过程就是 Redis 6.0 引入多线程来并发处理的</strong>。I/O 多路复用模块收到数据包之后将其丢给后面多个 I/O 线程进行解析，I/O 线程处理结束后，主线程会负责串行的执行这些命令，由于向客户端发回数据包的过程也是比较耗时的，所以<strong>执行之后的结果也会交给多个 I/O 线程发送回客户端</strong>。</p><hr><h2 id="数据结构与实现" tabindex="-1"><a class="header-anchor" href="#数据结构与实现" aria-hidden="true">#</a> 数据结构与实现</h2><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/image-20230227112105878.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="基本数据类型" tabindex="-1"><a class="header-anchor" href="#基本数据类型" aria-hidden="true">#</a> 基本数据类型</h3><h4 id="string-字符串" tabindex="-1"><a class="header-anchor" href="#string-字符串" aria-hidden="true">#</a> String（字符串）</h4><p>String是redis中最基本的数据类型，一个key对应一个value。底层数据结构是<strong>简单动态字符串（simple dynamic string, SDS</strong>），一个字符串的最大容量是512M。</p><p>主要好处有：</p><ul><li><strong>常数复杂度获取字符串长度</strong></li></ul><p>​ 由于 len 属性的存在，我们获取 SDS 字符串的长度只需要读取 len 属性，时间复杂度为 O(1)。而对于 C 语言，获取字符串的长度通常是经过遍历计数来实现的，时间复杂度为 O(n)。通过 <code>strlen key</code> 命令可以获取 key 的字符串长度。</p><ul><li><strong>杜绝缓冲区溢出</strong></li></ul><p>​ 我们知道在 C 语言中使用 <code>strcat</code> 函数来进行两个字符串的拼接，一旦没有分配足够长度的内存空间，就会造成缓冲区溢出。而对于 SDS 数据类型，在进行字符修改的时候，<strong>会首先根据记录的 len 属性检查内存空间是否满足需求</strong>，如果不满足，会进行相应的空间扩展，然后在进行修改操作，所以不会出现缓冲区溢出。</p><ul><li><strong>减少修改字符串的内存重新分配次数</strong></li></ul><p>​ C语言由于不记录字符串的长度，所以如果要修改字符串，必须要重新分配内存（先释放再申请），因为如果没有重新分配，字符串长度增大时会造成内存缓冲区溢出，字符串长度减小时会造成内存泄露。</p><p>而对于SDS，由于<code>len</code>属性和<code>alloc</code>属性的存在，对于修改字符串SDS实现了<strong>空间预分配</strong>和<strong>惰性空间释放</strong>两种策略：</p><p>1、<code>空间预分配</code>：对字符串进行空间扩展的时候，扩展的内存比实际需要的多，这样可以减少连续执行字符串增长操作所需的内存重分配次数。预分配，小于1MB的翻倍 ，大于上加1MB。</p><p>2、<code>惰性空间释放</code>：对字符串进行缩短操作时，程序不立即使用内存重新分配来回收缩短后多余的字节，而是使用 <code>alloc</code> 属性将这些字节的数量记录下来，等待后续使用。（当然SDS也提供了相应的API，当我们有需要时，也可以手动释放这些未使用的空间。）</p><ul><li><strong>二进制安全</strong></li></ul><p>​ 因为C字符串以空字符作为字符串结束的标识，而对于一些二进制文件（如图片等），内容可能包括空字符串，因此C字符串无法正确存取；而所有 SDS 的API 都是以处理二进制的方式来处理 <code>buf</code> 里面的元素，并且 SDS 不是以空字符串来判断是否结束，而是以 len 属性表示的长度来判断字符串是否结束。</p><ul><li><strong>兼容部分 C 字符串函数</strong></li></ul><p>​ 虽然 SDS 是二进制安全的，但是一样遵从每个字符串都是以空字符串结尾的惯例，这样可以重用 C 语言库<code>&lt;string.h&gt;</code> 中的一部分函数。</p><hr><h3 id="hash-哈希" tabindex="-1"><a class="header-anchor" href="#hash-哈希" aria-hidden="true">#</a> Hash（哈希）</h3><blockquote><p>Redis hash 是一个 string 类型的 field（字段） 和 value（值） 的映射表，hash 特别适合用于存储对象。底层数据结构是字典/哈希表，使用链地址法。</p><ul><li>什么叫渐进式 rehash？</li></ul><p>​ 也就是说扩容和收缩操作不是一次性、集中式完成的，而是分多次、渐进式完成的。如果保存在Redis中的键值对只有几个几十个，那么 rehash 操作可以瞬间完成，但是如果键值对有几百万，几千万甚至几亿，那么要一次性的进行 rehash，势必会造成Redis一段时间内不能进行别的操作。所以Redis采用渐进式 rehash,这样在进行渐进式rehash期间，字典的删除查找更新等操作可能会在两个哈希表上进行，第一个哈希表没有找到，就会去第二个哈希表上进行查找。但是进行增加操作，一定是在新的哈希表上进行的。<strong>如果当前正在进行重哈希，那么将重哈希过程向前推进一步（即调用_dictRehashStep）。实际上，除了查找，插入和删除也都会触发这一动作。这就将重哈希过程分散到各个查找、插入和删除操作中去了，而不是集中在某一个操作中一次性做完。</strong></p></blockquote><hr><h3 id="list-列表" tabindex="-1"><a class="header-anchor" href="#list-列表" aria-hidden="true">#</a> List（列表）</h3><blockquote><p>​ Redis中的List其实就是链表（Redis用双端链表实现List）。底层数据结构是快表，quicklist这个结构是Redis在3.2版本后新加的, 之前的版本是list(即linkedlist)， 用于String数据类型中。它是一种<strong>以ziplist为结点的双端链表结构</strong>. 宏观上, quicklist是一个链表, 微观上, 链表中的每个结点都是一个ziplist。</p><p>​ quicklist有自己的优点, 也有缺点, 对于使用者来说, 其使用体验类似于线性数据结构, list作为最传统的双链表, 结点通过指针持有数据, 指针字段会耗费大量内存. ziplist解决了耗费内存这个问题. 但引入了新的问题: 每次写操作整个ziplist的内存都需要重分配. quicklist在两者之间做了一个平衡. 并且使用者可以通过自定义<code>quicklist.fill</code>, 根据实际业务情况, 经验主义调参。</p></blockquote><p>ziplist本身也是一个能维持数据项先后顺序的列表（按插入位置），而且是一个内存紧缩的列表（各个数据项在内存上前后相邻）。比如，一个包含3个节点的quicklist，如果每个节点的ziplist又包含4个数据项，那么对外表现上，这个list就总共包含12个数据项。</p><p>quicklist的结构为什么这样设计呢？总结起来，大概又是一个空间和时间的折中：</p><ul><li>双向链表便于在表的两端进行push和pop操作，但是它的内存开销比较大。首先，它在每个节点上除了要保存数据之外，还要额外保存两个指针；其次，双向链表的各个节点是单独的内存块，地址不连续，节点多了容易产生内存碎片。</li><li>ziplist由于是一整块连续内存，所以存储效率很高。但是，它不利于修改操作，每次数据变动都会引发一次内存的realloc。特别是当ziplist长度很长的时候，一次realloc可能会导致大批量的数据拷贝，进一步降低性能。</li></ul>`,90),p={href:"http://oldhome.schmorp.de/marc/liblzf.html",target:"_blank",rel:"noopener noreferrer"},h=s('<hr><h3 id="set-集合" tabindex="-1"><a class="header-anchor" href="#set-集合" aria-hidden="true">#</a> Set（集合）</h3><blockquote><p>Redis 的 Set 是 String 类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。Redis 中集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。整数集合（<strong>IntSet</strong>）是集合类型的底层实现之一，当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis 就会使用整数集合作为集合键的底层实现。</p></blockquote><hr><h3 id="zset-sorted-set-有序集合" tabindex="-1"><a class="header-anchor" href="#zset-sorted-set-有序集合" aria-hidden="true">#</a> ZSet（Sorted Set 有序集合）</h3><blockquote><p>​ Redis 有序集合和集合一样也是 string 类型元素的集合，且不允许重复的成员。不同的是每个元素都会关联一个 double 类型的分数。redis 正是通过分数来为集合中的成员进行从小到大的排序。当sorted set 满足以下条件时使用压缩列表： <strong>成员的数量小于128 个。 每个member （成员）的字符串长度都小于64 个字节</strong>。当数据多的时候，sorted set是由一个叫zset的数据结构来实现的，这个zset包含一个dict + 一个skiplist。dict用来查询数据到分数(score)的对应关系，而skiplist用来根据分数查询数据（可能是范围查找）。</p></blockquote><p>有序集合的成员是唯一的, 但分数(score)却可以重复。有序集合是通过两种数据结构实现：</p><h4 id="压缩列表-ziplist" tabindex="-1"><a class="header-anchor" href="#压缩列表-ziplist" aria-hidden="true">#</a> <strong>压缩列表(ziplist)</strong></h4><p>ziplist是为了提高存储效率而设计的一种特殊编码的双向链表。它可以存储字符串或者整数，存储整数时是采用整数的二进制而不是字符串形式存储。它能在O(1)的时间复杂度下完成list两端的push和pop操作。但是因为每次操作都需要重新分配ziplist的内存，所以实际复杂度和ziplist的内存使用量相关。</p><blockquote><ul><li><p>为什么ZipList特别省内存</p><p>理解Entry结构，我们才会真正理解ZipList为什么是特别节省内存的数据结构。</p></li><li><p>ziplist节省内存是相对于普通的list来说的，如果是普通的数组，那么它每个元素占用的内存是一样的且取决于最大的那个元素（很明显它是需要预留空间的）；</p></li></ul><ol start="2"><li><p>所以ziplist在设计时就很容易想到要尽量让每个元素按照实际的内容大小存储，<strong>所以增加encoding字段</strong>，针对不同的encoding来细化存储大小；</p></li><li><p>这时候还需要解决的一个问题是遍历元素时如何定位下一个元素呢？在普通数组中每个元素定长，所以不需要考虑这个问题；但是ziplist中每个data占据的内存不一样，所以为了解决遍历，需要增加记录上一个元素的length，<strong>所以增加了prelen字段</strong>。</p></li></ol></blockquote><div class="language-html line-numbers-mode" data-ext="html"><pre class="language-html"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>zlbytes</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>zltail</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>zllen</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>entry</span><span class="token punctuation">&gt;</span></span>...<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>entry</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>zlend</span><span class="token punctuation">&gt;</span></span>\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>各个部分在内存上是前后相邻的，它们分别的含义如下：</p><ul><li><code>&lt;zlbytes&gt;</code>: 32bit，表示ziplist占用的字节总数（也包括<code>&lt;zlbytes&gt;</code>本身占用的4个字节）。</li><li><code>&lt;zltail&gt;</code>: 32bit，表示ziplist表中最后一项（entry）在ziplist中的偏移字节数。<code>&lt;zltail&gt;</code>的存在，使得我们可以很方便地找到最后一项（不用遍历整个ziplist），从而可以在ziplist尾端快速地执行push或pop操作。</li><li><code>&lt;zllen&gt;</code>: 16bit， 表示ziplist中数据项（entry）的个数。zllen字段因为只有16bit，所以可以表达的最大值为2<sup>16-1。这里需要特别注意的是，如果ziplist中数据项个数超过了16bit能表达的最大值，ziplist仍然可以来表示。那怎么表示呢？这里做了这样的规定：如果`&lt;zllen&gt;`小于等于2</sup>16-2（也就是不等于2^16-1），那么<code>&lt;zllen&gt;</code>就表示ziplist中数据项的个数；否则，也就是<code>&lt;zllen&gt;</code>等于16bit全为1的情况，那么<code>&lt;zllen&gt;</code>就不表示数据项个数了，这时候要想知道ziplist中数据项总数，那么必须对ziplist从头到尾遍历各个数据项，才能计数出来。</li><li><code>&lt;entry&gt;</code>: 表示真正存放数据的数据项，长度不定。一个数据项（entry）也有它自己的内部结构，这个稍后再解释。</li><li><code>&lt;zlend&gt;</code>: ziplist最后1个字节，是一个结束标记，值固定等于255。</li></ul><p>上面的定义中还值得注意的一点是：<code>&lt;zlbytes&gt;</code>, <code>&lt;zltail&gt;</code>, <code>&lt;zllen&gt;</code>既然占据多个字节，那么在存储的时候就有大端（big endian）和小端（little endian）的区别。ziplist采取的是小端模式来存储。</p><p>每一个数据项<code>&lt;entry&gt;</code>的构成：</p><div class="language-html line-numbers-mode" data-ext="html"><pre class="language-html"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>prevrawlen</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>len</span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>data</span><span class="token punctuation">&gt;</span></span>\n</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>我们看到在真正的数据（<code>&lt;data&gt;</code>）前面，还有两个字段：</p><ul><li><code>&lt;prevrawlen&gt;</code>: 表示前一个数据项占用的总字节数。这个字段的用处是为了让ziplist能够从后向前遍历（从后一项的位置，只需向前偏移prevrawlen个字节，就找到了前一项）。这个字段采用变长编码。</li><li><code>&lt;len&gt;</code>: 表示当前数据项的数据长度（即<code>&lt;data&gt;</code>部分的长度）。也采用变长编码。</li></ul><p>例子：</p>',19),g={href:"http://zhangtielei.com/assets/photos_redis/redis_ziplist_sample.png",target:"_blank",rel:"noopener noreferrer"},u=e("img",{src:"https://raw.githubusercontent.com/nocetfy/image/main/img/redis_ziplist_sample.png",alt:"Redis Ziplist Sample",tabindex:"0",loading:"lazy"},null,-1),f=e("figcaption",null,"Redis Ziplist Sample",-1),m=e("p",null,"上图是一份真实的ziplist数据。我们逐项解读一下：",-1),b=e("li",null,"这个ziplist一共包含33个字节。字节编号从byte[0]到byte[32]。图中每个字节的值使用16进制表示。",-1),k=e("code",null,"<zlbytes>",-1),y={href:"https://en.wikipedia.org/wiki/Endianness",target:"_blank",rel:"noopener noreferrer"},R=e("code",null,"<zlbytes>",-1),x=s("<li>接下来4个字节（byte[4..7]）是<code>&lt;zltail&gt;</code>，用小端存储模式来解释，它的值是0x0000001D（值为29），表示最后一个数据项在byte[29]的位置（那个数据项为0x05FE14）。</li><li>再接下来2个字节（byte[8..9]），值为0x0004，表示这个ziplist里一共存有4项数据。</li><li>接下来6个字节（byte[10..15]）是第1个数据项。其中，prevrawlen=0，因为它前面没有数据项；len=4，相当于前面定义的9种情况中的第1种，表示后面4个字节按字符串存储数据，数据的值为”name”。</li><li>接下来8个字节（byte[16..23]）是第2个数据项，与前面数据项存储格式类似，存储1个字符串”tielei”。</li><li>接下来5个字节（byte[24..28]）是第3个数据项，与前面数据项存储格式类似，存储1个字符串”age”。</li><li>接下来3个字节（byte[29..31]）是最后一个数据项，它的格式与前面的数据项存储格式不太一样。其中，第1个字节prevrawlen=5，表示前一个数据项占用5个字节；第2个字节=FE，相当于前面定义的9种情况中的第8种，所以后面还有1个字节用来表示真正的数据，并且以整数表示。它的值是20（0x14）。</li><li>最后1个字节（byte[32]）表示<code>&lt;zlend&gt;</code>，是固定的值255（0xFF）。</li>",7),v=e("p",null,"总结一下，这个ziplist里存了4个数据项，分别为：",-1),_=e("ul",null,[e("li",null,"字符串: “name”"),e("li",null,"字符串: “tielei”"),e("li",null,"字符串: “age”"),e("li",null,"整数: 20")],-1),z=e("h4",{id:"跳跃表-zskiplist",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#跳跃表-zskiplist","aria-hidden":"true"},"#"),i(),e("strong",null,"跳跃表（zSkiplist)")],-1),S=e("p",null,[i("​ 跳跃表的性能可以保证在查找，删除，添加等操作的时候在对数期望时间内完成，这个性能是可以和平衡树来相比较的，而且在实现方面比平衡树要优雅，这是采用跳跃表的主要原因。跳跃表的复杂度是"),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mi",null,"O"),e("mo",{stretchy:"false"},"("),e("mi",null,"l"),e("mi",null,"o"),e("mi",null,"g"),e("mi",null,"n"),e("mo",{stretchy:"false"},")")]),e("annotation",{encoding:"application/x-tex"},"O(logn)")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),e("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"O"),e("span",{class:"mopen"},"("),e("span",{class:"mord mathnormal",style:{"margin-right":"0.01968em"}},"l"),e("span",{class:"mord mathnormal"},"o"),e("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"g"),e("span",{class:"mord mathnormal"},"n"),e("span",{class:"mclose"},")")])])]),i("。")],-1),q=s('<figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/skiplist_insertions.png" alt="skiplist插入形成过程" tabindex="0" loading="lazy"><figcaption>skiplist插入形成过程</figcaption></figure><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/search_path_on_skiplist.png" alt="skiplist上的查找路径展示" tabindex="0" loading="lazy"><figcaption>skiplist上的查找路径展示</figcaption></figure><h5 id="redis中一个跳表的可能结构" tabindex="-1"><a class="header-anchor" href="#redis中一个跳表的可能结构" aria-hidden="true">#</a> Redis中一个跳表的可能结构</h5><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/redis_skiplist_example.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>注意：图中前向指针上面括号中的数字，表示对应的span的值。即当前指针跨越了多少个节点，这个计数不包括指针的起点节点，但包括指针的终点节点。</p><p>​ 假设我们在这个skiplist中查找score=89.0的元素（即Bob的成绩数据），在查找路径中，我们会跨域图中标红的指针，这些指针上面的span值累加起来，就得到了Bob的排名(2+2+1)-1=4（减1是因为rank值以0起始）。需要注意这里算的是从小到大的排名，而如果要算从大到小的排名，只需要用skiplist长度减去查找路径上的span累加值，即6-(2+2+1)=1。</p><p>​ 可见，在查找skiplist的过程中，通过累加span值的方式，我们就能很容易算出排名。相反，如果指定排名来查找数据（类似zrange和zrevrange那样），也可以不断累加span并时刻保持累加值不超过指定的排名，通过这种方式就能得到一条O(log n)的查找路径。</p><h5 id="为什么redis用跳表" tabindex="-1"><a class="header-anchor" href="#为什么redis用跳表" aria-hidden="true">#</a> 为什么Redis用跳表</h5><blockquote><ol><li><p>skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个key的查找，不适宜做范围查找。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。</p></li><li><p>在做范围查找的时候，平衡树比skiplist操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。</p></li><li><p>平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。</p></li><li><p>从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。</p></li><li><p>查找单个key，skiplist和平衡树的时间复杂度都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。</p></li><li><p>从算法实现难度上来比较，skiplist比平衡树要简单得多。</p></li></ol></blockquote><h3 id="压缩" tabindex="-1"><a class="header-anchor" href="#压缩" aria-hidden="true">#</a> 压缩</h3><p>Redis对于元素个数少和value小的数据有压缩算法，可以降低Redis的数据结构开销，redis采用压缩时要求的元素个数如下：</p><table><thead><tr><th style="text-align:center;">类型</th><th style="text-align:center;">最大个数</th><th style="text-align:center;">value最大长度</th><th style="text-align:center;">压缩与标准数据结构</th></tr></thead><tbody><tr><td style="text-align:center;">Hash</td><td style="text-align:center;">512</td><td style="text-align:center;">64</td><td style="text-align:center;">ZipList -&gt; Dict</td></tr><tr><td style="text-align:center;">List</td><td style="text-align:center;">512</td><td style="text-align:center;">64</td><td style="text-align:center;">ZipList -&gt; QuickList</td></tr><tr><td style="text-align:center;">Set</td><td style="text-align:center;">512</td><td style="text-align:center;">使用字符串</td><td style="text-align:center;">IntSet -&gt; Dict</td></tr><tr><td style="text-align:center;">Sorted Set</td><td style="text-align:center;">128</td><td style="text-align:center;">64</td><td style="text-align:center;">ZipList -&gt; ZSet(Dict + SkipList)</td></tr></tbody></table><h3 id="key规范" tabindex="-1"><a class="header-anchor" href="#key规范" aria-hidden="true">#</a> key规范</h3><ul><li>key不大于16336字节</li><li>String：大小控制在 10KB 以下</li><li>List/Hash/Set/ZSet：元素数量尽量控制在1000以下</li></ul><hr><h2 id="过期删除策略与内存淘汰策略" tabindex="-1"><a class="header-anchor" href="#过期删除策略与内存淘汰策略" aria-hidden="true">#</a> 过期删除策略与内存淘汰策略</h2><h3 id="过期删除策略" tabindex="-1"><a class="header-anchor" href="#过期删除策略" aria-hidden="true">#</a> 过期删除策略</h3><p>在单机版Redis中，存在两种删除策略：</p><ul><li><code>惰性删除</code>：服务器不会主动删除数据，只有当客户端查询某个数据时，服务器判断该数据是否过期，如果过期则删除。</li><li><code>定期删除</code>：服务器执行定时任务删除过期数据，但是考虑到内存和CPU的折中（删除会释放内存，但是频繁的删除操作对CPU不友好），该删除的频率和执行时间都受到了限制。</li></ul><p>​ 在主从复制场景下，为了主从节点的数据一致性，从节点不会主动删除数据，而是由主节点控制从节点中过期数据的删除。由于主节点的惰性删除和定期删除策略，都不能保证主节点及时对过期数据执行删除操作，因此，当客户端通过Redis从节点读取数据时，很容易读取到已经过期的数据。Redis 3.2中，从节点在读取数据时，增加了对数据是否过期的判断：如果该数据已过期，则不返回给客户端</p><h3 id="内存淘汰策略" tabindex="-1"><a class="header-anchor" href="#内存淘汰策略" aria-hidden="true">#</a> 内存淘汰策略</h3><p>如果达到设置的上限，Redis的写命令会触发淘汰策略，读请求不受影响，淘汰策略如下：</p><ul><li><p><code>noeviction</code> - 当内存使用达到阈值的时候，所有引起申请内存的命令会报错。这是 Redis 默认的策略。</p></li><li><p><code>allkeys-lru</code> - 在主键空间中，优先移除最近未使用的 key。</p></li><li><p><code>allkeys-lfu</code>：不管 key 是否设置了过期，淘汰访问频率最低的 key（4.0+版本支持）</p></li><li><p><code>allkeys-random</code> - 在主键空间中，随机移除某个 key。</p></li><li><p><code>volatile-lru</code> - 在设置了过期时间的键空间中，优先移除最近未使用的 key。</p></li><li><p><code>volatile-lfu</code>：只淘汰访问频率最低、并设置了过期时间 key（4.0+版本支持）</p></li><li><p><code>volatile-random</code> - 在设置了过期时间的键空间中，随机移除某个 key。</p></li><li><p><code>volatile-ttl</code> - 在设置了过期时间的键空间中，具有更早过期时间的 key 优先移除。</p></li></ul><hr><h2 id="事务" tabindex="-1"><a class="header-anchor" href="#事务" aria-hidden="true">#</a> 事务</h2><p>​ Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。总结说：<strong>redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令</strong>。</p><blockquote><p>MULTI 、 EXEC 、 DISCARD 和 WATCH 是 Redis 事务相关的命令。</p></blockquote><ul><li>MULTI ：开启事务，redis会将后续的命令逐个放入队列中，然后使用EXEC命令来原子化执行这个命令系列。</li><li>EXEC：执行事务中的所有操作命令。</li><li>DISCARD：取消事务，放弃执行事务块中的所有命令。</li><li>WATCH：监视一个或多个key,如果事务在执行前，这个key(或多个key)被其他命令修改，则事务被中断，不会执行事务中的任何命令。</li><li>UNWATCH：取消WATCH对所有key的监视。</li></ul><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/db-redis-trans-1.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h4 id="为什么-redis-不支持回滚" tabindex="-1"><a class="header-anchor" href="#为什么-redis-不支持回滚" aria-hidden="true">#</a> 为什么 Redis 不支持回滚</h4><ul><li>Redis 命令只会因为错误的语法而失败（并且这些问题不能在入队时发现），或是命令用在了错误类型的键上面：这也就是说，从实用性的角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发的过程中被发现，而不应该出现在生产环境中。</li><li>因为不需要对回滚进行支持，所以 Redis 的内部可以保持简单且快速。</li><li>Redis官方文档给的理解是：Redis的事务是原子性的：所有的命令，要么全部执行，<strong>要么全部不执行。而不是完全成功</strong>。</li></ul><hr><h2 id="pipeline" tabindex="-1"><a class="header-anchor" href="#pipeline" aria-hidden="true">#</a> Pipeline</h2><p>​ 虽然池化的connection，节省了建立连接的时间，但多条命令(发送命令到sever、server返回结果)分别执行多次socket网络IO，涉及到read()和write() syscall系统调用，这意味着从用户态到内核态。上下文切换是巨大的速度损失。如果能将多条命令“合并”到一起，进行一次网络IO，性能会提高很多，这就是<strong>pipeline</strong></p><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/image-20230227203235761.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>​ 从Redis的RESP协议上看，pipeline并没有什么特殊的地方，只是把多个命令连续的发送给redis-server，然后一一解析返回结果。Jedis客户端缓存是8192，超过该大小则刷新缓存，或者直接发送。</p><p>​ pipeline 只能用于执行连续且无相关性的命令，当某个命令的生成需要依赖于前一个命令的返回时(或需要一起执行时)，就无法使用 pipeline 了。通过 scripting 功能，可以规避这一局限性。</p><h3 id="与事务-multi-的区别" tabindex="-1"><a class="header-anchor" href="#与事务-multi-的区别" aria-hidden="true">#</a> 与事务(multi)的区别</h3><ol><li>pipeline选择客户端缓冲，multi选择服务端队列缓冲。</li><li>求次数的不一致，multi需要每个命令都发送一次给服务端，pipeline最后一次性发送给服务端，请求次数相对于multi减少。</li><li>multi/exec可以保证原子性，而pipeline不保证原子性。</li></ol><hr><h2 id="持久化" tabindex="-1"><a class="header-anchor" href="#持久化" aria-hidden="true">#</a> 持久化</h2><p>Redis 支持两种持久化方式：RDB 和 AOF。</p><h3 id="rdb" tabindex="-1"><a class="header-anchor" href="#rdb" aria-hidden="true">#</a> RDB</h3><p>RDB 即某一时刻的二进制数据快照。Redis 会周期性生成 RDB 文件。默认会使用LZF算法进行压缩。 生成 RDB 流程：Redis fork 一个子进程，负责生成 RDB；生成 RDB 采用 Copy On Write 模式，此时，如果收到写请求，会在原副本上操作，不影响工作。 RDB 只能恢复生成快照时刻的数据，之后的数据无法恢复。生成 RDB 的资源开销高昂。RDB 适合做冷备。</p><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/redis-x-rdb-1.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/2021-12-10-003342.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h4 id="为什么用子进程" tabindex="-1"><a class="header-anchor" href="#为什么用子进程" aria-hidden="true">#</a> 为什么用子进程</h4><ol><li>通过 <code>fork</code> 创建的子进程能够获得和父进程完全相同的内存空间，父进程对内存的修改对于子进程是不可见的，两者不会相互影响。</li><li>通过 <code>fork</code> 创建子进程时不会立刻触发大量内存的拷贝，内存在被修改时会以页为单位进行拷贝，这也就避免了大量拷贝内存而带来的性能问题。</li></ol><blockquote><ul><li>线程会共享内存可能还需要处理竞争条件的问题，进程有独立的内存空间，实现上会简单很多。</li><li>如果用线程来做快照，在做快照的过程中，所有写操作会立即对redis状态产生影响，这样最终做出来的快照整体上就不是全局一致的了，即可能出现一个快照中，有些部分的数据较新（在快照阶段后期持久化），有些数据版本更老（在快照阶段前期持久化）。</li></ul></blockquote><h3 id="aof" tabindex="-1"><a class="header-anchor" href="#aof" aria-hidden="true">#</a> AOF</h3><p>​ AOF 会将写命令不断追加到 AOF 文本日志末尾。AOF日志采用写后日志，即<strong>先写内存，后写日志</strong>。AOF 丢数据比 RDB 少，但文件会比 RDB 文件大很多。一般，AOF 设置 appendfsync 同步频率为 <strong>everysec</strong> 即可，此时会使用<strong>子线程</strong>执行<code>save</code>操作，如果每个命令都写AOF，会阻塞主线程。</p><p>​ 从我们发送写指令开始到指令保存在AOF文件中，需要经历4步，分别为<strong>命令传播</strong>、<strong>命令追加</strong>、<strong>文件写入</strong>和<strong>文件同步</strong>。</p><p>​ 建议同时使用 RDB 和 AOF。用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。</p><p>​ <code>AOF「重写」</code>，新AOF文件的生成并非是在原AOF文件的基础上进行操作得到的，而是读取Redis当前的数据状态来重新生成的。不难理解，后者的处理方式远比前者高效。</p><p>为了避免阻塞主线程，导致数据库性能下降，和 AOF 日志由主进程写回不同，重写过程是由子进程执行<code>bgrewriteaof</code>来完成的。这样处理的最大好处是：</p><ol><li>子进程进行 AOF重写期间，主进程可以继续处理命令请求；</li><li>子进程带有主进程的数据副本，操作效率更高。</li></ol><p>这里有两个问题值得我们来思考一下</p><blockquote><p>1.为什么使用子进程，而不是多线程来进行AOF重写呢？</p></blockquote><p>​ 如果是使用线程，线程之间会共享内存，在修改共享内存数据的时候，需要通过加锁来保证数据的安全，这样就会降低性能。</p><p>​ 如果使用子进程，操作系统会使用<strong>写时复制</strong>的技术：<code>fork</code>子进程时，子进程会拷贝父进程的页表，即虚实映射关系，而不会拷贝物理内存。子进程复制了父进程页表，也能共享访问父进程的内存数据，达到共享内存的效果。</p><p>​ 不过这个共享的内存只能以只读的方式，<strong>当父子进程任意一方修改了该共享内存，就会发生「写时复制」</strong>，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。</p><h4 id="redis-执行持久化时-可以处理请求吗" tabindex="-1"><a class="header-anchor" href="#redis-执行持久化时-可以处理请求吗" aria-hidden="true">#</a> Redis 执行持久化时，可以处理请求吗？</h4><blockquote><p>可以，RDB 采用 Copy On Write 模式，此时，如果收到写请求，会在原副本上操作，不影响工作。AOF异步写，不影响主线程。为所有从库开启<code>AOF</code>。</p></blockquote><hr><h2 id="主从复制" tabindex="-1"><a class="header-anchor" href="#主从复制" aria-hidden="true">#</a> 主从复制</h2><h3 id="主从复制的作用" tabindex="-1"><a class="header-anchor" href="#主从复制的作用" aria-hidden="true">#</a> 主从复制的作用</h3><ul><li><strong>数据冗余</strong>：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。</li><li><strong>故障恢复</strong>：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。</li><li><strong>负载均衡</strong>：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。</li><li><strong>高可用基石</strong>：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。</li></ul><h3 id="主从复制原理" tabindex="-1"><a class="header-anchor" href="#主从复制原理" aria-hidden="true">#</a> 主从复制原理</h3><h4 id="全量复制" tabindex="-1"><a class="header-anchor" href="#全量复制" aria-hidden="true">#</a> 全量复制</h4><ul><li><code>全量（同步）复制</code>：比如第一次同步时</li></ul><p>​ 当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前使用 slaveof）命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。</p><h5 id="全量复制的三个阶段" tabindex="-1"><a class="header-anchor" href="#全量复制的三个阶段" aria-hidden="true">#</a> 全量复制的三个阶段</h5><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/db-redis-copy-2.jpg" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>第一阶段是主从库间建立连接、协商同步的过程</strong>，主要是为全量复制做准备。在这一步，从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了。</p><p>具体来说，从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。psync 命令包含了主库的 runID 和复制进度 offset 两个参数。runID，是每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设为“？”。offset，此时设为 -1，表示第一次复制。主库收到 psync 命令后，会用 FULLRESYNC 响应命令带上两个参数：主库 runID 和主库目前的复制进度 offset，返回给从库。从库收到响应后，会记录下这两个参数。这里有个地方需要注意，FULLRESYNC 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库。</p><p><strong>第二阶段，主库将所有数据同步给从库</strong>。从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成的 RDB 文件。</p><p>具体来说，主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。否则，Redis 的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中。为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作。</p><p><strong>第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库</strong>。具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。</p><hr><h4 id="增量复制" tabindex="-1"><a class="header-anchor" href="#增量复制" aria-hidden="true">#</a> 增量复制</h4><ul><li><code>增量（同步）复制</code>：只会把主从库网络断连期间主库收到的命令，同步给从库。</li></ul><h5 id="为什么会设计增量复制" tabindex="-1"><a class="header-anchor" href="#为什么会设计增量复制" aria-hidden="true">#</a> 为什么会设计增量复制</h5><p>​ 如果主从库在命令传播时出现了网络闪断，那么，从库就会和主库重新进行一次全量复制，开销非常大。从 Redis 2.8 开始，网络断了之后，主从库会采用增量复制的方式继续同步。</p><h5 id="增量复制的流程" tabindex="-1"><a class="header-anchor" href="#增量复制的流程" aria-hidden="true">#</a> 增量复制的流程</h5><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/db-redis-copy-3.jpg" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>先看两个概念： <code>replication buffer</code> 和 <code>repl_backlog_buffer</code></p><p><code>repl_backlog_buffer</code>：它是为了从库断开之后，如何找到主从差异数据而设计的环形缓冲区，从而避免全量复制带来的性能开销。如果从库断开时间太久，repl_backlog_buffer环形缓冲区被主库的写命令覆盖了，那么从库连上主库后只能乖乖地进行一次全量复制，所以<strong>repl_backlog_buffer配置尽量大一些，可以降低主从断开后全量复制的概率</strong>。而在repl_backlog_buffer中找主从差异的数据后，如何发给从库呢？这就用到了replication buffer。</p><p><code>replication buffer</code>：Redis和客户端通信也好，和从库通信也好，Redis都需要给分配一个 内存buffer进行数据交互，客户端是一个client，从库也是一个client，我们每个client连上Redis后，Redis都会分配一个client buffer，所有数据交互都是通过这个buffer进行的：Redis先把数据写到这个buffer中，然后再把buffer中的数据发到client socket中再通过网络发送出去，这样就完成了数据交互。所以主从在增量同步时，从库作为一个client，也会分配一个buffer，只不过这个buffer专门用来传播用户的写命令到从库，保证主从数据一致，我们通常把它叫做replication buffer。</p><ul><li><strong>如果在网络断开期间，repl_backlog_size环形缓冲区写满之后，从库是会丢失掉那部分被覆盖掉的数据，还是直接进行全量复制呢</strong>？</li></ul><p>对于这个问题来说，有两个关键点：</p><ol><li>一个从库如果和主库断连时间过长，造成它在主库repl_backlog_buffer的slave_repl_offset位置上的数据已经被覆盖掉了，此时从库和主库间将进行全量复制。</li><li>每个从库会记录自己的slave_repl_offset，每个从库的复制进度也不一定相同。在和主库重连进行恢复时，从库会通过psync命令把自己记录的slave_repl_offset发给主库，主库会根据从库各自的复制进度，来决定这个从库可以进行增量复制，还是全量复制。</li></ol><h3 id="为什么主从全量复制使用rdb而不使用aof" tabindex="-1"><a class="header-anchor" href="#为什么主从全量复制使用rdb而不使用aof" aria-hidden="true">#</a> 为什么主从全量复制使用RDB而不使用AOF？</h3><ol><li><p>RDB文件内容是经过压缩的二进制数据（不同数据类型数据做了针对性优化），文件很小。而AOF文件记录的是每一次写操作的命令，写操作越多文件会变得很大，其中还包括很多对同一个key的多次冗余操作。在主从全量数据同步时，传输RDB文件可以尽量降低对主库机器网络带宽的消耗，从库在加载RDB文件时，一是文件小，读取整个文件的速度会很快，二是因为RDB文件存储的都是二进制数据，从库直接按照RDB协议解析还原数据即可，速度会非常快，而AOF需要依次重放每个写命令，这个过程会经历冗长的处理逻辑，恢复速度相比RDB会慢得多，所以使用RDB进行主从全量复制的成本最低。</p></li><li><p>假设要使用AOF做全量复制，意味着必须打开AOF功能，打开AOF就要选择文件刷盘的策略，选择不当会严重影响Redis性能。而RDB只有在需要定时备份和主从全量复制数据时才会触发生成一次快照。而在很多丢失数据不敏感的业务场景，其实是不需要开启AOF的。</p></li></ol><hr><h2 id="高可用" tabindex="-1"><a class="header-anchor" href="#高可用" aria-hidden="true">#</a> 高可用</h2><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/20230227165749.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h3 id="主从模型" tabindex="-1"><a class="header-anchor" href="#主从模型" aria-hidden="true">#</a> 主从模型</h3><p>Redis 基本都通过“主 - 从”模式进行部署，<strong>主从库之间采用的是读写分离的方式。</strong></p><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/640-20230227195924476.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>​ 同 MySQL 类似，<strong>主库支持写和读，从库只支持读，数据会先写到主库，然后定时同步给从库</strong>，具体的同步规则，主要将 RDB 日志从主库同步给从库，然后从库读取 RDB 日志，这里比较复杂，其中还涉及到 replication buffer，就不再展开。</p><p>​ 这里有个问题，一次同步过程中，主库需要完成 2 个耗时操作：生成 RDB 文件和传输 RDB 文件。如果从库数量过多，主库忙于 fock 子进程生成 RDB 文件和数据同步，会阻塞主库正常请求。这个如何解决呢？<strong>答案是 “主 - 从 - 从” 模式。</strong></p><p>​ 为了避免所有从库都从主库同步 RDB 日志，可以借助从库来完成同步：比如新增 3、4 两个 Slave，可以<strong>等 Slave 2 同步完后，再通过 Slave 2 同步给 Slave 3 和 Slave 4。</strong></p><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/640-20230227195936206.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><h3 id="哨兵机制-sentinel" tabindex="-1"><a class="header-anchor" href="#哨兵机制-sentinel" aria-hidden="true">#</a> 哨兵机制(Sentinel)</h3><p>在主从模式下，如果 master 宕机了，从库不能从主库同步数据，主库也不能提供读写功能。</p><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/640-20230227200039315.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p><strong>怎么办呢 ？这时就需要引入哨兵机制 ！哨兵节点是特殊的 Redis 服务，不提供读写服务，主要用来监控 Redis 实例节点。</strong></p><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/640-20230227200039772.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><blockquote><p>​ 哨兵实例之间可以相互发现，要归功于 Redis 提供的 pub/sub 机制，也就是发布 / 订阅机制。通过这个方式，哨兵 2 和 3 也可以建立网络连接，这样一来，哨兵集群就形成了。它们相互间可以通过网络连接进行通信，比如说对主库有没有下线这件事儿进行判断和协商。</p></blockquote><p>那么当 master 宕机，哨兵如何执行呢？</p><h4 id="判断主机下线" tabindex="-1"><a class="header-anchor" href="#判断主机下线" aria-hidden="true">#</a> 判断主机下线</h4><p>​ 哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态，如果哨兵发现主库或从库对 PING 命令的响应超时了，哨兵就会先把它标记为“主观下线”。那是否一个哨兵判断为“主观下线”，就直接下线 master 呢？答案肯定是不行的，需要遵循 “少数服从多数” 原则：<strong>有 N/2+1 个实例判断主库“主观下线”，才判定主库为“客观下线”。</strong></p><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/640-20230227200040205.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>比如上图有 3 个哨兵，有 2 个判断 “主观下线”，那么就标记主库为 “客观下线”。</p><h4 id="哨兵集群选举" tabindex="-1"><a class="header-anchor" href="#哨兵集群选举" aria-hidden="true">#</a> 哨兵集群选举</h4><p>​ 为了避免哨兵的单点情况发生，所以需要一个哨兵的分布式集群。作为分布式集群，必然涉及共识问题（即选举问题）。同时故障的转移和通知都只需要一个主的哨兵节点就可以了。哨兵的选举机制其实很简单，就是一个Raft选举算法： <strong>选举的票数大于等于num(sentinels)/2+1时，将成为领导者，如果没有超过，继续选举</strong>。</p><ul><li>任何一个想成为 Leader 的哨兵，要满足两个条件： <ul><li>第一，拿到半数以上的赞成票；</li><li>第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。</li></ul></li></ul><h4 id="选取新主库" tabindex="-1"><a class="header-anchor" href="#选取新主库" aria-hidden="true">#</a> 选取新主库</h4><p>我们有 5 个从库，需要选取一个最优的从库作为主库，分 2 步：</p><ul><li><strong>筛选</strong>：检查从库的当前在线状态和之前的网络连接状态，过滤不适合的从库；</li><li><strong>打分</strong>：根据从库优先级、和旧主库的数据同步接近度进行打分，选最高分作为主库。</li></ul><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/640-20230227200040516.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>​ <strong>如果分数一致怎么办 ？</strong> Redis 也有一个策略：ID 号最小的从库得分最高，会被选为新主库。当 slave 3 选举为新主库后，<strong>会通知其它从库和客户端，对外宣布自己是新主库</strong>。</p><h4 id="例子" tabindex="-1"><a class="header-anchor" href="#例子" aria-hidden="true">#</a> 例子</h4><p><strong>判定客观下线</strong> 和 <strong>是否能够主从切换（用到选举机制）</strong> 是两个概念，我们再看一个例子。</p><ul><li>Redis 1主4从，5个哨兵，哨兵配置quorum为2，如果3个哨兵故障，当主库宕机时，哨兵能否判断主库“客观下线”？能否自动切换？</li></ul><ol><li><p>哨兵集群可以判定主库“主观下线”。由于quorum=2，所以当一个哨兵判断主库“主观下线”后，询问另外一个哨兵后也会得到同样的结果，2个哨兵都判定“主观下线”，达到了quorum的值，因此，<strong>哨兵集群可以判定主库为“客观下线”</strong>。</p></li><li><p><strong>但哨兵不能完成主从切换</strong>。哨兵标记主库“客观下线后”，在选举“哨兵领导者”时，一个哨兵必须拿到超过多数的选票(5/2+1=3票)。但目前只有2个哨兵活着，无论怎么投票，一个哨兵最多只能拿到2票，永远无法达到<code>N/2+1</code>选票的结果。</p></li></ol><hr><h3 id="集群" tabindex="-1"><a class="header-anchor" href="#集群" aria-hidden="true">#</a> 集群</h3><hr><h4 id="twemproxy" tabindex="-1"><a class="header-anchor" href="#twemproxy" aria-hidden="true">#</a> twemproxy</h4>',130),B={href:"https://github.com/twitter/twemproxy",target:"_blank",rel:"noopener noreferrer"},D=e("strong",null,"解决的重点就是把客户端分片的逻辑统一放到了Proxy层而已",-1),w={href:"https://kaito-blog-1253469779.cos.ap-beijing.myqcloud.com/2020/07/15941324303761.jpg",target:"_blank",rel:"noopener noreferrer"},L=e("img",{src:"https://raw.githubusercontent.com/nocetfy/image/main/img/15941324303761.jpg",alt:"Twemproxy架构图",tabindex:"0",loading:"lazy"},null,-1),A=e("figcaption",null,"Twemproxy架构图",-1),O=s('<p>​ Tweproxy推出的时间最久，在早期没有好的服务端分片集群方案时，应用范围很广，而且性能也极其稳定。但它的痛点就是<strong>无法在线扩容、缩容</strong>，这就导致运维非常不方便，而且也没有友好的运维UI可以使用。Codis就是因为在这种背景下才衍生出来的。</p><hr><h3 id="redis-cluster" tabindex="-1"><a class="header-anchor" href="#redis-cluster" aria-hidden="true">#</a> Redis Cluster</h3><p>​ Redis-cluster是一种服务器Sharding技术，Redis3.0以后版本正式提供支持。设计目标是高性能可线性扩展至最多1000节点。集群中没有代理，（集群节点间）使用异步复制，没有归并操作。</p><h4 id="哈希槽-hash-slot" tabindex="-1"><a class="header-anchor" href="#哈希槽-hash-slot" aria-hidden="true">#</a> 哈希槽(Hash Slot)</h4><p>Redis-cluster没有使用一致性hash，而是引入了<strong>哈希槽</strong>的概念。Redis-cluster中有16384(即2的14次方）个哈希槽，每个key通过CRC16校验后对16383取模来决定放置哪个槽。Cluster中的每个节点负责一部分hash槽（hash slot）。</p><p>比如集群中存在三个节点，则可能存在的一种分配如下：</p><ul><li>节点A包含0到5500号哈希槽；</li><li>节点B包含5501到11000号哈希槽；</li><li>节点C包含11001 到 16384号哈希槽。</li></ul><h5 id="为什么是16384" tabindex="-1"><a class="header-anchor" href="#为什么是16384" aria-hidden="true">#</a> 为什么是16384</h5><p>​ Redis-cluster没有使用一致性hash，而是引入了哈希槽的概念。Redis-cluster中有16384(即2的14次方）个哈希槽，每个key通过CRC16校验后对16383取模来决定放置哪个槽。Cluster中的每个节点负责一部分hash槽（hash slot）。 ​ 虽然使用CRC16算法最多可以分配65535（2^16-1）个槽位，65535=65k，压缩后就是8k（8 * 8 (8 bit) * 1024(1k) =65K），也就是说需要需要8k的心跳包，作者认为这样做不太值得；并且一般情况下一个redis集群不会有超过1000个master节点，所以16k的槽位是个比较合适的选择。</p><h4 id="扩容-缩容" tabindex="-1"><a class="header-anchor" href="#扩容-缩容" aria-hidden="true">#</a> 扩容&amp;缩容</h4><blockquote><p>扩容：先增加节点到集群，然后把槽指定到新节点上，会把槽上所有数据都迁移到新节点。</p></blockquote><blockquote><p>缩容：先把槽位指定到其他节点上，然后再从集群中移除节点。</p></blockquote><hr><h2 id="常见问题" tabindex="-1"><a class="header-anchor" href="#常见问题" aria-hidden="true">#</a> 常见问题</h2><h3 id="缓存穿透" tabindex="-1"><a class="header-anchor" href="#缓存穿透" aria-hidden="true">#</a> 缓存穿透</h3><blockquote><p>在缓存中查询不到数据，去数据库中查询数据也没查到，相当于无效请求到了DB，有大量这样请求都打到了DB。</p></blockquote><p>解决方案：</p><ul><li>接口层增加校验，如用户鉴权校验，id做基础校验，id&lt;=0的直接拦截。</li><li>从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击。</li><li>布隆过滤器。bloomfilter就类似于一个hash set，用于快速判某个元素是否存在于集合中，其典型的应用场景就是快速判断一个key是否存在于某容器，不存在就直接返回。布隆过滤器的关键就在于hash算法和容器大小。</li></ul><hr><h3 id="缓存击穿" tabindex="-1"><a class="header-anchor" href="#缓存击穿" aria-hidden="true">#</a> 缓存击穿</h3><blockquote><p>​ 缓存击穿是指<strong>缓存中没有但数据库中有的数据</strong>（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。</p></blockquote><p>解决方案：</p><ul><li>设置热点数据永远不过期。</li><li>接口限流与熔断，降级。重要的接口一定要做好限流策略，防止用户恶意刷接口，同时要降级准备，当接口中的某些服务不可用时候，进行熔断，失败快速返回机制。</li><li>加互斥锁，这是比较常用的方法，简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去查询数据库，而是先使用缓存工具的某些带成功操作返回值的操作（<code>SETNX</code>）去 <code>set</code> 一个 <code>mutex key</code>，当操作返回成功时，再进行查询数据库的操作并回设缓存；否则，就重试整个 get 缓存的方法。</li></ul><hr><h3 id="缓存雪崩" tabindex="-1"><a class="header-anchor" href="#缓存雪崩" aria-hidden="true">#</a> 缓存雪崩</h3><blockquote><p>​ 缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。</p></blockquote><p>典型原因：</p><p>​ 选择一致性 Hash 分布方式，同时在部分节点异常时，采用 rehash 策略，即把异常节点请求平均分散到其他缓存节点。在一般情况下，一致性 Hash 分布+rehash 策略可以很好得运行，但在较大的流量洪峰到临之时，如果大流量 key 比较集中，正好在某 1～2 个缓存节点，很容易将这些缓存节点的内存、网卡过载，缓存节点异常 Crash，然后这些异常节点下线，这些大流量 key 请求又被 rehash 到其他缓存节点，进而导致其他缓存节点也被过载 Crash，缓存异常持续扩散，最终导致整个缓存体系异常，无法对外提供服务。</p><p>解决方案：</p><ul><li>缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。</li><li>如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。</li><li>设置热点数据永远不过期。</li><li>对缓存体系进行实时监控，当请求访问的慢速比超过阀值时，及时报警，通过机器替换、服务替换进行及时恢复；也可以通过各种自动故障转移策略，自动关闭异常接口、停止边缘服务、停止部分非核心功能措施，确保在极端场景下，核心功能的正常运行。</li><li>对缓存增加多个副本，缓存异常或请求 miss 后，再读取其他缓存副本，而且多个缓存副本尽量部署在不同机架，从而确保在任何情况下，缓存系统都会正常对外提供服务。</li></ul><hr><h3 id="保证缓存与数据库一致性" tabindex="-1"><a class="header-anchor" href="#保证缓存与数据库一致性" aria-hidden="true">#</a> 保证缓存与数据库一致性</h3><p><strong>在满足实时性的条件下，不存在两者完全保存一致的方案，只有最终一致性方案。</strong> 根据众多解决方案，总结出 6 种，直接看目录：</p><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/640.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><h4 id="先写-mysql-再写-redis" tabindex="-1"><a class="header-anchor" href="#先写-mysql-再写-redis" aria-hidden="true">#</a> 先写 MySQL，再写 Redis</h4><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/640-20230227195001551.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><blockquote><p>图解说明：</p><ul><li>这是一副时序图，描述请求的先后调用顺序；</li><li>橘黄色的线是请求 A，黑色的线是请求 B；</li><li>橘黄色的文字，是 MySQL 和 Redis 最终不一致的数据；</li><li>数据是从 10 更新为 11；</li><li>后面所有的图，都是这个含义，不再赘述。</li></ul></blockquote><p>​ 请求 A、B 都是先写 MySQL，然后再写 Redis，在高并发情况下，如果请求 A 在写 Redis 时卡了一会，请求 B 已经依次完成数据的更新，就会出现图中的问题。<strong>这里有个前提，就是对于读请求，先去读 Redis，如果没有，再去读 DB，但是读请求不会再回写 Redis。</strong> 大白话说一下，就是读请求不会更新 Redis。</p><h4 id="先写-redis-再写-mysql" tabindex="-1"><a class="header-anchor" href="#先写-redis-再写-mysql" aria-hidden="true">#</a> 先写 Redis，再写 MySQL</h4><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/640-20230227195001968.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><h4 id="先删除-redis-再写-mysql" tabindex="-1"><a class="header-anchor" href="#先删除-redis-再写-mysql" aria-hidden="true">#</a> 先删除 Redis，再写 MySQL</h4><p>这幅图和上面有些不一样，前面的请求 A 和 B 都是更新请求，这里的请求 A 是更新请求，<strong>但是请求 B 是读请求，且请求 B 的读请求会回写 Redis。</strong></p><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/640-20230227195002187.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>​ 请求 A 先删除缓存，可能因为卡顿，数据一直没有更新到 MySQL，导致两者数据不一致。<strong>这种情况出现的概率比较大，因为请求 A 更新 MySQL 可能耗时会比较长，而请求 B 的前两步都是查询，会非常快。</strong></p><h4 id="先删除-redis-再写-mysql-再删除-redis" tabindex="-1"><a class="header-anchor" href="#先删除-redis-再写-mysql-再删除-redis" aria-hidden="true">#</a> 先删除 Redis，再写 MySQL，再删除 Redis</h4><p>对于“先删除 Redis，再写 MySQL”，如果要解决最后的不一致问题，其实再对 Redis 重新删除即可，<strong>这个也是大家常说的“缓存双删”。</strong></p><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/640-20230227195002472.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>​ 为了便于大家看图，对于蓝色的文字，“删除缓存 10”必须在“回写缓存10”后面，那如何才能保证一定是在后面呢？<strong>网上给出的第一个方案是，让请求 A 的最后一次删除，等待 500ms</strong>。对于这种方案，看看就行，反正我是不会用，太 Low 了，风险也不可控。<strong>那有没有更好的方案呢，异步串行化删除，即删除请求入队列</strong>。</p><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/640-20230227195002754.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>​ 异步删除对线上业务无影响，串行化处理保障并发情况下正确删除。如果双删失败怎么办，网上有给 Redis 加一个缓存过期时间的方案，这个不敢苟同。<strong>个人建议整个重试机制，可以借助消息队列的重试机制，也可以自己整个表，记录重试次数</strong>，方法很多。</p><blockquote><p>简单小结一下：</p><ul><li>“缓存双删”不要用无脑的 sleep 500 ms；</li><li>通过消息队列的异步&amp;串行，实现最后一次缓存删除；</li><li>缓存删除失败，增加重试机制。</li></ul></blockquote><h4 id="先写-mysql-再删除-redis" tabindex="-1"><a class="header-anchor" href="#先写-mysql-再删除-redis" aria-hidden="true">#</a> 先写 MySQL，再删除 Redis</h4><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/640-20230227195002889.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>​ 对于上面这种情况，对于第一次查询，请求 B 查询的数据是 10，但是 MySQL 的数据是 11，<strong>只存在这一次不一致的情况，对于不是强一致性要求的业务，可以容忍。</strong>（那什么情况下不能容忍呢，比如秒杀业务、库存服务等。）当请求 B 进行第二次查询时，因为没有命中 Redis，会重新查一次 DB，然后再回写到 Reids。</p><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/640-20230227195021351.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>这里需要满足 2 个条件：</p><ul><li>缓存刚好自动失效；</li><li>请求 B 从数据库查出 10，回写缓存的耗时，比请求 A 写数据库，并且删除缓存的还长。</li></ul><p>对于第二个条件，我们都知道更新 DB 肯定比查询耗时要长，所以出现这个情况的概率很小，同时满足上述条件的情况更小。</p><h4 id="先写-mysql-通过-binlog-异步更新-redis" tabindex="-1"><a class="header-anchor" href="#先写-mysql-通过-binlog-异步更新-redis" aria-hidden="true">#</a> 先写 MySQL，通过 Binlog，异步更新 Redis</h4><p>这种方案，主要是监听 MySQL 的 Binlog，然后通过异步的方式，将数据更新到 Redis，这种方案有个前提，查询的请求，不会回写 Redis。</p><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/640-20230227195015681.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>​ 这个方案，会保证 MySQL 和 Redis 的最终一致性，但是如果中途请求 B 需要查询数据，如果缓存无数据，就直接查 DB；如果缓存有数据，查询的数据也会存在不一致的情况。<strong>所以这个方案，是实现最终一致性的终极解决方案，但是不能保证实时性。</strong></p><blockquote><p>​ 订阅变更日志的思想，本质是把权威数据源（例如 MySQL）当做 leader 副本，让其它异质系统（例如 Redis / Elasticsearch）成为它的 follower 副本，通过同步变更日志的方式，保证 leader 和 follower 之间保持一致。</p></blockquote><h4 id="方案对比" tabindex="-1"><a class="header-anchor" href="#方案对比" aria-hidden="true">#</a> 方案对比</h4><p>我们对比上面讨论的 6 种方案：</p><ol><li>先写 Redis，再写 MySQL</li></ol><blockquote><ul><li><strong>这种方案，我肯定不会用</strong>，万一 DB 挂了，你把数据写到缓存，DB 无数据，这个是灾难性的；</li><li>我之前也见同学这么用过，如果写 DB 失败，对 Redis 进行逆操作，那如果逆操作失败呢，是不是还要搞个重试？</li></ul></blockquote><ol start="2"><li>先写 MySQL，再写 Redis</li></ol><blockquote><ul><li><strong>对于并发量、一致性要求不高的项目，很多就是这么用的</strong>，我之前也经常这么搞，但是不建议这么做；</li><li>当 Redis 瞬间不可用的情况，需要报警出来，然后线下处理。</li></ul></blockquote><ol start="3"><li>先删除 Redis，再写 MySQL</li></ol><blockquote><p>这种方式，我还真没用过，<strong>直接忽略吧。</strong></p></blockquote><ol start="4"><li>先删除 Redis，再写 MySQL，再删除 Redis</li></ol><ul><li>这种方式虽然可行，但是<strong>感觉好复杂</strong>，还要搞个消息队列去异步删除 Redis。</li></ul><ol start="5"><li>先写 MySQL，再删除 Redis</li></ol><blockquote><ul><li><strong>比较推荐这种方式</strong>，删除 Redis 如果失败，可以再多重试几次，否则报警出来；</li><li>这个方案，是实时性中最好的方案，在一些高并发场景中，推荐这种。</li></ul></blockquote><ol start="6"><li>先写 MySQL，通过 Binlog，异步更新 Redis</li></ol><blockquote><ul><li><strong>对于异地容灾、数据汇总等，建议会用这种方式</strong>，比如 binlog + kafka，数据的一致性也可以达到秒级；</li><li>纯粹的高并发场景，不建议用这种方案，比如抢购、秒杀等。</li></ul></blockquote><h4 id="结论" tabindex="-1"><a class="header-anchor" href="#结论" aria-hidden="true">#</a> 结论</h4><ul><li><strong>实时一致性方案</strong>：采用“先写 MySQL，再删除 Redis”的策略，这种情况虽然也会存在两者不一致，但是需要满足的条件有点苛刻，<strong>所以是满足实时性条件下，能尽量满足一致性的最优解。</strong></li><li><strong>最终一致性方案</strong>：采用“先写 MySQL，通过 Binlog，异步更新 Redis”，可以通过 Binlog，结合消息队列异步更新 Redis，<strong>是最终一致性的最优解。</strong></li></ul><hr><h3 id="redis-keys执行了会怎么样" tabindex="-1"><a class="header-anchor" href="#redis-keys执行了会怎么样" aria-hidden="true">#</a> redis keys执行了会怎么样</h3><ol><li>当redis集群中的key数量不多时候没有什么大问题，但是随着key数量的增长，这样可能引起redis的客户端访问redis阻塞。</li><li>因为Redis是单线程的，执行任何命令时候其他命令会阻塞，而且由于key命令的时间复杂度是O(n)，redis服务端会匹配查找完所有的key才结束，比较耗时，如果在线上执行非常危险。</li><li>如果命令执行时间过长可能会触发服务器的安全策略，导致主从切换或者重新选主。(在线上环境配置下，<strong>主从切换必丢数据</strong>)</li></ol><hr><h3 id="热key" tabindex="-1"><a class="header-anchor" href="#热key" aria-hidden="true">#</a> 热key</h3><h4 id="什么是热key" tabindex="-1"><a class="header-anchor" href="#什么是热key" aria-hidden="true">#</a> 什么是热key</h4><p>所谓的热key，就是访问频率高比较的key。比如，热门新闻事件或商品，这类key通常有大流量的访问，对存储这类信息的 Redis来说，是不小的压力</p><h4 id="热key的问题" tabindex="-1"><a class="header-anchor" href="#热key的问题" aria-hidden="true">#</a> 热key的问题</h4><p>​ Redis集群部署，热key可能会造成整体流量的不均衡，个别节点出现OPS过大的情况，极端情况下热点key甚至会超过 Redis本身能够承受的QPS，引发主从切换或者重新选主，会导致丢数据。</p><h4 id="怎么找到热key" tabindex="-1"><a class="header-anchor" href="#怎么找到热key" aria-hidden="true">#</a> 怎么找到热key</h4><ol><li>客户端 客户端其实是距离key“最近”的地方，因为Redis命令就是从客户端发出的，例如在客户端设置全局字典（key和调用次数），每次调用Redis命令时，使用这个字典进行记录。</li><li>代理端 像Twemproxy、Codis这些基于代理的Redis分布式架构，所有客户端的请求都是通过代理端完成的，可以在代理端进行收集统计。</li><li>Redis服务端 使用monitor命令统计热点key是很多开发和运维人员首先想到，monitor命令可以监控到Redis执行的所有命令。</li></ol><h4 id="怎么处理热key" tabindex="-1"><a class="header-anchor" href="#怎么处理热key" aria-hidden="true">#</a> 怎么处理热key</h4><ol><li>扩容，增加redis实例副本数量</li><li>二级缓存，把热key加载到本地内存</li><li>热key备份</li></ol><p>如何将对某个热 <code>Key</code> 的请求打散到不同实例上呢？我们就可以通过热 <code>Key</code> 备份的方式，基本的思路就是，我们可以给热 <code>Key</code> 加上前缀或者后缀，把一个热 <code>Key</code> 的数量变成 <code>Redis</code> 实例个数 <code>N</code> 的倍数 <code>M</code>，从而由访问一个 <code>Redis</code> <code>Key</code> 变成访问 <code>N * M</code> 个 <code>Redis</code> <code>Key</code>。 <code>N * M</code> 个 <code>Redis</code> <code>Key</code> 经过分片分布到不同的实例上，将访问量均摊到所有实例。</p><hr><h3 id="大key" tabindex="-1"><a class="header-anchor" href="#大key" aria-hidden="true">#</a> 大key</h3><h4 id="什么是大key" tabindex="-1"><a class="header-anchor" href="#什么是大key" aria-hidden="true">#</a> 什么是大key</h4><ul><li>单个简单的key存储的value很大，size超过10KB</li><li>hash， set，zset，list 中存储过多的元素（以万为单位）</li></ul><h4 id="大key的问题" tabindex="-1"><a class="header-anchor" href="#大key的问题" aria-hidden="true">#</a> 大key的问题</h4><ul><li>客户端耗时增加，甚至超时</li><li>对大key进行IO操作时，会严重占用带宽和CPU</li><li>造成Redis集群中数据倾斜</li><li>主动删除、被动删等，可能会导致阻塞</li></ul><h4 id="怎么查找大key" tabindex="-1"><a class="header-anchor" href="#怎么查找大key" aria-hidden="true">#</a> 怎么查找大key</h4><ul><li>bigkeys命令：使用bigkeys命令以遍历的方式分析Redis实例中的所有Key，并返回整体统计信息与每个数据类型中Top1的大Key</li><li>redis-rdb-tools：redis-rdb-tools是由Python写的用来分析Redis的rdb快照文件用的工具，它可以把rdb快照文件生成json文件或者生成报表用来分析Redis的使用详情。</li></ul><h4 id="怎么处理大key" tabindex="-1"><a class="header-anchor" href="#怎么处理大key" aria-hidden="true">#</a> 怎么处理大key</h4><ul><li><p><strong>删除大key</strong></p></li><li><ul><li>当Redis版本大于4.0时，可使用UNLINK命令安全地删除大Key，该命令能够以非阻塞的方式，逐步地清理传入的Key。 <ul><li>当Redis版本小于4.0时，避免使用阻塞式命令KEYS，而是建议通过SCAN命令执行增量迭代扫描key，然后判断进行删除。</li></ul></li></ul></li><li><p><strong>压缩和拆分key</strong></p></li><li><ul><li>当vaule是string时，比较难拆分，则使用序列化、压缩算法将key的大小控制在合理范围内，但是序列化和反序列化都会带来更多时间上的消耗。 <ul><li>当value是string，压缩之后仍然是大key，则需要进行拆分，一个大key分为不同的部分，记录每个部分的key，使用multiget等操作实现事务读取。</li><li>当value是list/set等集合类型时，根据预估的数据规模来进行分片，不同的元素计算后分到不同的片。</li></ul></li></ul></li><li><blockquote><p>能拆就拆，不能拆再压缩。</p></blockquote></li></ul><figure><img src="https://raw.githubusercontent.com/nocetfy/image/main/img/640-20230227234743497.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><hr><h2 id="性能优化" tabindex="-1"><a class="header-anchor" href="#性能优化" aria-hidden="true">#</a> 性能优化</h2><ol><li>Master 最好不要做 RDB 持久化，因为这时 save 命令调度 rdbSave 函数，会阻塞主线程的工作，当数据集比较大时可能造成主线程间断性暂停服务。AOF最好也不要做。</li><li>如果数据比较重要，将某个 Slave 节点开启AOF数据备份，策略设置为每秒一次。</li><li>为了主从复制速度和连接的稳定性，Master 和 Slave 最好在同一个局域网中。</li><li>尽量避免在运行压力很大的主库上增加从库。</li><li>主从复制不要用图状结构，用单向链表结构更为稳定，<code>Mater-&gt;Slave1-&gt;Slave2-&gt;Slave3...</code> 这样的结构方便解决单点故障问题，实现 Slave 对 Master 的替换，如果 Master 崩溃，可以立即启用 Slave1替换Mater，而其他依赖关系则保持不变。</li><li>客户端使用长连接，池化连接，避免频繁创建连接。</li><li>尽量使用pipeline，减少网络IO的损耗。</li></ol><h3 id="线上性能" tabindex="-1"><a class="header-anchor" href="#线上性能" aria-hidden="true">#</a> 线上性能</h3><p>单分片4G内存，对外宣称1w的qps，实际专属云2.4w的qps，私有云翻倍。</p><hr><h2 id="命令执行过程" tabindex="-1"><a class="header-anchor" href="#命令执行过程" aria-hidden="true">#</a> 命令执行过程</h2><ol><li>远程客户端连接到 redis 后，redis服务端会为远程客户端创建一个 redisClient 作为代理。</li><li>redis 会读取socket中的数据，写入 querybuf 中。</li><li>解析 querybuf 中的命令，记录到 argc 和 argv 中。</li><li>根据 argv[0] 查找对应的 recommand。</li><li>执行 recommend 对应的执行函数。</li><li>执行以后将结果存入 buf &amp; bufpos &amp; reply 中。</li><li>返回给调用方。返回数据的时候，会控制写入数据量的大小，如果过大会分成若干次。保证 redis 的响应时间。</li></ol><p>​ Redis 作为单线程应用，一直贯彻的思想就是，每个步骤的执行都有一个上限（包括执行时间的上限或者文件尺寸的上限）一旦达到上限，就会记录下当前的执行进度，下次再执行。保证了 Redis 能够及时响应不发生阻塞。</p><hr>',115);function C(M,F){const a=l("ExternalLinkIcon");return o(),r("div",null,[c,e("p",null,[i("​ 当列表很长的时候，最容易被访问的很可能是两端的数据，中间的数据被访问的频率比较低（访问起来性能也很低）。如果应用场景符合这个特点，那么list还提供了一个选项，能够把中间的数据节点进行压缩，从而进一步节省内存空间，quicklist的头节点和尾节点总是不被压缩的，以便于在表的两端进行快速存取。Redis对于quicklist内部节点的压缩算法，采用的"),e("a",p,[i("LZF"),t(a)]),i("——一种无损压缩算法。")]),h,e("figure",null,[e("a",g,[u,t(a)]),f]),m,e("ul",null,[b,e("li",null,[i("头4个字节（0x21000000）是按小端（little endian）模式存储的"),k,i("字段。什么是小端呢？就是指数据的低字节保存在内存的低地址中（参见维基百科词条"),e("a",y,[i("Endianness"),t(a)]),i("）。因此，这里"),R,i("的值应该解析成0x00000021，用十进制表示正好就是33。")]),x]),v,_,z,S,q,e("p",null,[i("​ "),e("a",B,[i("Twemproxy"),t(a)]),i("是由Twitter开源的集群化方案，它既可以做Redis Proxy，还可以做Memcached Proxy。它的功能比较单一，只实现了请求路由转发，没有像Codis那么全面有在线扩容的功能，它"),D,i("，其他功能没有做任何处理。")]),e("figure",null,[e("a",w,[L,t(a)]),A]),O])}const E=n(d,[["render",C],["__file","Redis.html.vue"]]);export{E as default};
