import{_ as t,X as d,Y as l,$ as i}from"./framework-47f15ee6.js";const o={},e=i('<h1 id="基础" tabindex="-1"><a class="header-anchor" href="#基础" aria-hidden="true">#</a> 基础</h1><ul><li>消息队列的优缺点</li></ul><p>优点：</p><blockquote><ul><li>解耦</li></ul><p>​ 对于项目的变化，很难预测到未来的变动。消息中间件在处理过程中间插入了一个隐含、基于数据的接口层，两边的处理过程都要实现这一接口，但是两边都可以独立的扩展或则修改自己的处理过程，只要确保他们遵守同样的接口约束即可</p><ul><li>异步</li></ul><p>​ 传统模式下使用串行接口调用的方式，一些非必要的业务逻辑以同步的方式运行，阻塞后续接口的调用，耗费时间。如果使用消息中间件方式，将消息写入消息队列，非必要的业务逻辑以异步的方式运行，可以加快响应速度。</p><ul><li>削峰</li></ul><p>​ 一个系统访问流量有高峰时期，也有低峰时期，如果高峰期流量太大，我们的系统、数据库可能就会崩溃。这时如果使用 MQ 进行流量削峰，将用户的大量消息直接放到 MQ 里面，然后我们的系统去按自己的最大消费能力去消费这些消息，就可以保证系统的稳定，随后跟进业务逻辑，给用户返回特定页面或者稍后通过其他方式通知其结果。</p></blockquote><p>缺点：</p><blockquote><ul><li>系统可用性降低</li></ul><p>在系统中引入 MQ，需要考虑MQ服务挂掉的风险与后续的补偿。一般而言，引入的外部依赖越多，系统越脆弱，每一个依赖出问题都会导致整个系统的崩溃。</p><ul><li>系统复杂度提高</li></ul><p>需要考虑 MQ 的各种情况，比如：消息的重复消费、消息丢失、保证消息传递的顺序性等等。</p><ul><li>数据一致性问题</li></ul><p>比如 A 系统已经给客户返回操作成功，这时候操作 BC 都成功了，操作 D 却失败了，导致数据不一致。</p></blockquote><ul><li>消息队列选型</li></ul><table><thead><tr><th>特性</th><th>RabbitMQ</th><th>RocketMQ</th><th>Kafka</th></tr></thead><tbody><tr><td>单机吞吐量</td><td>万级</td><td>十万级</td><td>百万级</td></tr><tr><td>时效性</td><td>μs级</td><td>ms级</td><td>ms级</td></tr><tr><td>可用性</td><td>高 主从，采用镜像模式实现</td><td>非常高 分布式，主从</td><td>非常高 分布式，主从</td></tr><tr><td>消费模式</td><td>推 + 拉</td><td>拉</td><td>拉</td></tr><tr><td>死信队列</td><td>支持</td><td>支持</td><td>不支持</td></tr><tr><td>延迟队列</td><td>支持</td><td>支持</td><td>不支持</td></tr><tr><td>支持协议</td><td>AMQP、MQTT、STOMP</td><td>自定义</td><td>自定义</td></tr><tr><td>消息顺序</td><td>条件苛刻，需要单线程发送，单线程消费并不采用延迟队列、优先级队列</td><td>支持</td><td>支持单分区顺序</td></tr><tr><td>消息存储</td><td>内存、磁盘</td><td>磁盘</td><td>内存、磁盘、数据库</td></tr><tr><td>消息回溯</td><td>不支持</td><td>支持指定时间点的回溯</td><td>支持指定分区offset位置的回溯</td></tr><tr><td>优点</td><td>erlang 语言开发，性能极好、延时很低、MQ 功能完备，管理界面非常好，社区活跃</td><td>接口简单易用，吞吐量大，分布式扩展方便、社区比较活跃，支持大规模的 Topic、支持复杂的业务场景，可以基于源码进行定制开发</td><td>超高吞吐量，ms 级的时延，极高的可用性和可靠性，分布式扩展方便</td></tr><tr><td>缺点</td><td>吞吐量较低，erlang 语言开发不容易进行定制开发，集群动态扩展麻烦</td><td>没在MQ核心实现JMS等接口，broker主从切换不能自动实现，早期多语言SDK支持不够</td><td>消息队列功能较为简单，MQ高级功能支持不足</td></tr><tr><td>应用</td><td>都有应用</td><td>用于大规模吞吐、复杂业务中</td><td>在大数据的实时计算和日志采集中被大规模使用</td></tr></tbody></table><ul><li>拉模式和推模式的区别</li></ul><blockquote><ul><li>推模式</li></ul><p>​ 实时性强，客户端实现简单。但是容易由于消费端消费慢造成消息堆积的情况，对消息队列造成压力。且不易实现顺序消费，需要苛刻的保证单线程生产，单线程消费，确认后再继续消费，更加加重堆积情况。</p><ul><li>拉模式</li></ul><p>​ 不会造成消息积压。但是可能有消息延迟和忙等问题。可以通过长轮询解决。对于顺序消息支持较好。</p></blockquote><ul><li>怎么确保消息不丢失</li></ul><blockquote><ul><li>生产者</li></ul><p>要求是，leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。</p><ul><li>MQ</li></ul><p>​ 可以通过配置刷盘和复制相关的参数，让消息写入到多个副本的磁盘上，来确保消息不会因为某个 Broker 宕机或者磁盘损坏而丢失，足够多的replica写成功后，才认为写成功，否则让生产者重试。</p><ul><li>消费者</li></ul><p>关闭自动ack，处理完全部消费业务逻辑之后，再手动ack，同时需要确保消息的幂等性。</p></blockquote><ul><li>怎么确保消息不被重复消费</li></ul><blockquote><p>​ 首先我们需要为消息生成一个全局唯一ID，将ID作为数据库主键，就可以进行去重。即在消费消息前，执行insert操作，如果抛出主键冲突异常就代表已经被消费了，消息可以丢弃。</p></blockquote><ul><li>怎么保证消息的顺序性</li></ul><blockquote><p>​ 发送消息时指定key，会做hash，相同key的消息必定会发送到相同的partition，kafka保证同一partition只能被同一消费者消费，即可保证消费者得到的消息是顺序的，如果消费者使用多线程消费，则需要维护队列，同一key先投入LIFO队列，再使用线程池，同一线程只读取一个队列的消息。</p></blockquote><ul><li>怎么处理消息积压</li></ul><blockquote><p>​ 快速扩容，增加消费者(也可以加线程)来处理积压，如果积压很厉害，而且消费实例数已经超过partition数量，需要新建topic，多加partition，然后原topic的消息消费后发到新topic上去，扩容的机器消费新topic下的消息，完毕后再恢复回来。</p></blockquote>',18),r=[e];function u(p,c){return d(),l("div",null,r)}const k=t(o,[["render",u],["__file","基础.html.vue"]]);export{k as default};
